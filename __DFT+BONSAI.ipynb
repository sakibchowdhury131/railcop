{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "__DFT+BONSAI.ipynb",
      "provenance": [],
      "mount_file_id": "19ZTLbkwoSQYssoiRBcbPHFzbLxchGb53",
      "authorship_tag": "ABX9TyMEHW9awHX8HHGAV4Coq2+g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakibchowdhury131/railcop/blob/main/__DFT%2BBONSAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-4d4ZklblM9",
        "outputId": "70ba03db-5171-413e-f541-f4476c94950c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJZlYQxLWv3_",
        "outputId": "4b151eb5-9fe3-4fbb-d376-992038e4c090"
      },
      "source": [
        "!git clone https://github.com/microsoft/EdgeML.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'EdgeML' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGBFGfTSW7cS",
        "outputId": "7555e5be-4ea6-4870-986a-6432b786427c"
      },
      "source": [
        "%cd /content/EdgeML/tf/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EdgeML/tf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exXQ3dzbYohk",
        "outputId": "3b953f98-2149-4651-d42c-51650865eeaa"
      },
      "source": [
        "!pip install -r requirements-cpu.txt\n",
        "!pip install -e ."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: antlr4-python3-runtime==4.7 in /usr/local/lib/python3.7/dist-packages (from -r requirements-cpu.txt (line 1)) (4.7)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements-cpu.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: numpy==1.16.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements-cpu.txt (line 3)) (1.16.4)\n",
            "Requirement already satisfied: pandas==0.23.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements-cpu.txt (line 4)) (0.23.4)\n",
            "Requirement already satisfied: scikit-learn==0.21.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements-cpu.txt (line 5)) (0.21.2)\n",
            "Requirement already satisfied: scipy==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements-cpu.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: tensorflow==1.15.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements-cpu.txt (line 7)) (1.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements-cpu.txt (line 8)) (2.23.0)\n",
            "Requirement already satisfied: bokeh==2.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements-cpu.txt (line 9)) (2.1.1)\n",
            "Requirement already satisfied: onnx==1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements-cpu.txt (line 10)) (1.8.0)\n",
            "Requirement already satisfied: tqdm==4.56.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements-cpu.txt (line 11)) (4.56.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (4.10.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (5.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (5.6.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (5.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (5.3.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (7.6.5)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.7/dist-packages (from pandas==0.23.4->-r requirements-cpu.txt (line 4)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from pandas==0.23.4->-r requirements-cpu.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.2->-r requirements-cpu.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (1.15.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (1.41.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (1.13.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (0.37.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.1.1->-r requirements-cpu.txt (line 9)) (5.1.1)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.1.1->-r requirements-cpu.txt (line 9)) (2.11.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.1.1->-r requirements-cpu.txt (line 9)) (21.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.1.1->-r requirements-cpu.txt (line 9)) (3.10.0.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.1.1->-r requirements-cpu.txt (line 9)) (3.13)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.1.1->-r requirements-cpu.txt (line 9)) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.7->bokeh==2.1.1->-r requirements-cpu.txt (line 9)) (2.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (3.1.0)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh==2.1.1->-r requirements-cpu.txt (line 9)) (2.4.7)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (4.8.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements-cpu.txt (line 8)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements-cpu.txt (line 8)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements-cpu.txt (line 8)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements-cpu.txt (line 8)) (3.0.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->-r requirements-cpu.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (5.3.5)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (0.2.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (1.0.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (3.5.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (5.1.3)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (4.9.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (4.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (0.5.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter==1.0.0->-r requirements-cpu.txt (line 2)) (1.11.2)\n",
            "Obtaining file:///content/EdgeML/tf\n",
            "Installing collected packages: edgeml-tf\n",
            "  Attempting uninstall: edgeml-tf\n",
            "    Found existing installation: edgeml-tf 0.3.0\n",
            "    Can't uninstall 'edgeml-tf'. No files were found to uninstall.\n",
            "  Running setup.py develop for edgeml-tf\n",
            "Successfully installed edgeml-tf-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbdCxpp5Wx6O"
      },
      "source": [
        "### Defining Bonsai Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C8CtFzNYyet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed5175b-8e5c-44e8-a4ba-886edaf0753b"
      },
      "source": [
        "%cd /content/EdgeML/examples/tf/Bonsai\n",
        "import helpermethods"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EdgeML/examples/tf/Bonsai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3igz9s-ZNGP"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "\n",
        "#Provide the GPU number to be used\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] =''\n",
        "\n",
        "#Bonsai imports\n",
        "from edgeml_tf.trainer.bonsaiTrainer import BonsaiTrainer\n",
        "from edgeml_tf.graph.bonsai import Bonsai\n",
        "\n",
        "# Fixing seeds for reproducibility\n",
        "tf.set_random_seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwBbdKz5hHoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8790b19d-5582-457e-e1d7-613a8878beda"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import pandas as pd\n",
        "print(pd.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.23.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK4WfmLUCxO_",
        "outputId": "9bb50003-df74-44d2-fc55-bd1131ad6f3a"
      },
      "source": [
        "label0 = pd.read_csv('/content/drive/MyDrive/RailCop/New Files/Sakib/data/label0/Copy of train_1.csv')\n",
        "label1 = pd.read_csv('/content/drive/MyDrive/RailCop/New Files/Sakib/data/label1/Copy of train_1.csv')\n",
        "print(label1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Sensor1           ...             Sensor1+Sensor2+Sensor3\n",
            "0           2           ...                                  12\n",
            "1           4           ...                                  13\n",
            "2           4           ...                                  15\n",
            "3           4           ...                                  16\n",
            "4           2           ...                                  12\n",
            "5           5           ...                                  13\n",
            "6           3           ...                                  11\n",
            "7           4           ...                                  15\n",
            "8           3           ...                                  14\n",
            "9           4           ...                                  13\n",
            "10          3           ...                                  13\n",
            "11          3           ...                                  13\n",
            "12          4           ...                                  12\n",
            "13          4           ...                                  14\n",
            "14          4           ...                                  14\n",
            "15          4           ...                                  16\n",
            "16          4           ...                                  14\n",
            "17          3           ...                                  12\n",
            "18          4           ...                                  14\n",
            "19          4           ...                                  12\n",
            "20          4           ...                                  14\n",
            "21          3           ...                                  13\n",
            "22          3           ...                                  12\n",
            "23          3           ...                                  11\n",
            "24          3           ...                                  16\n",
            "25          3           ...                                  13\n",
            "26          4           ...                                  13\n",
            "27          4           ...                                  16\n",
            "28          3           ...                                  14\n",
            "29          3           ...                                  12\n",
            "...       ...           ...                                 ...\n",
            "5359        4           ...                                  16\n",
            "5360        4           ...                                  14\n",
            "5361        4           ...                                  15\n",
            "5362        4           ...                                  14\n",
            "5363        4           ...                                  14\n",
            "5364        4           ...                                  15\n",
            "5365        4           ...                                  14\n",
            "5366        5           ...                                  17\n",
            "5367        5           ...                                  14\n",
            "5368        5           ...                                  15\n",
            "5369        5           ...                                  14\n",
            "5370        5           ...                                  15\n",
            "5371        3           ...                                  14\n",
            "5372        4           ...                                  13\n",
            "5373        3           ...                                  13\n",
            "5374        3           ...                                  11\n",
            "5375        5           ...                                  15\n",
            "5376        5           ...                                  14\n",
            "5377        3           ...                                  14\n",
            "5378        4           ...                                  13\n",
            "5379        4           ...                                  13\n",
            "5380        3           ...                                  14\n",
            "5381        3           ...                                  15\n",
            "5382        4           ...                                  13\n",
            "5383        4           ...                                  14\n",
            "5384        3           ...                                  13\n",
            "5385        3           ...                                  14\n",
            "5386        4           ...                                  13\n",
            "5387        3           ...                                  13\n",
            "5388        3           ...                                  15\n",
            "\n",
            "[5389 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSHgZYxHEQjv",
        "outputId": "be77a40b-0e14-47ae-d40c-fac06de1e55f"
      },
      "source": [
        "__fullVector0 = label0['Sensor1+Sensor2+Sensor3'].as_matrix()\n",
        "__fullVector1 = label1['Sensor1+Sensor2+Sensor3'].as_matrix()\n",
        "\n",
        "\n",
        "print(__fullVector0.shape)\n",
        "print(__fullVector1.shape)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23050,)\n",
            "(5389,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxHOcgAKEzFD"
      },
      "source": [
        "__frameSize = 50\n",
        "\n",
        "## label 0 framing\n",
        "\n",
        "__numFrames0 = int(__fullVector0.shape[0] / __frameSize)\n",
        "__frames0 = np.zeros((__numFrames0,__frameSize))\n",
        "for i in range (0, __numFrames0):\n",
        "  for j in range (0, __frameSize):\n",
        "    __frames0[i][j] = __fullVector0[i*__frameSize+j]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLdPYaw6InIu"
      },
      "source": [
        "## label 1 framing\n",
        "\n",
        "__numFrames1 = int(__fullVector1.shape[0] / __frameSize)\n",
        "__frames1 = np.zeros((__numFrames1,__frameSize))\n",
        "for i in range (0, __numFrames1):\n",
        "  for j in range (0, __frameSize):\n",
        "    __frames1[i][j] = __fullVector1[i*__frameSize+j]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaiwVxH2JDM1",
        "outputId": "f7a193f4-88fc-4592-f145-579fa29e3ad5"
      },
      "source": [
        "__frames0.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(461, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcL-0u7tJIe8",
        "outputId": "4a98e90b-1b8c-4594-b106-9a269fbbc344"
      },
      "source": [
        "__frames1.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(107, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCU13F4tJR58"
      },
      "source": [
        "__maxFrames = __frames1.shape[0]\n",
        "__label0 = __frames0[0:__maxFrames, :]\n",
        "__label1 = __frames1[0:__maxFrames, :]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HuAiNmf6NnQ",
        "outputId": "d7cb599a-e927-41b3-cc0f-bffa97a673c0"
      },
      "source": [
        "Y0 = np.zeros(__label0.shape[0])\n",
        "Y1 = np.ones(__label1.shape[0])\n",
        "print(Y0.shape)\n",
        "print(Y1.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(107,)\n",
            "(107,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0fbc4SIPY13"
      },
      "source": [
        "## Applying DFT\n",
        "## finding Fourier Co-efficients Xn\n",
        "\n",
        "def get_xn(samples,n):\n",
        "    L  = len(samples)\n",
        "    ks = np.arange(0,L,1)\n",
        "    xn = np.sum(samples*np.exp((1j*2*np.pi*ks*n)/L))/L\n",
        "    return(xn)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vsN2UOEPzP2"
      },
      "source": [
        "## Compute Fourier coefficients only up to the Nyquest Limit Xn, n=1,...,L/2 and \n",
        "## multiply the absolute value of the Fourier coefficients by 2, to account for \n",
        "## the symetry of the Fourier coefficients above the Nyquest Limit.\n",
        "\n",
        "\n",
        "def get_xns(samples):\n",
        "    mag = []\n",
        "    L = len(samples)\n",
        "    for n in range(int(L/2)): # Nyquest Limit\n",
        "        mag.append(np.abs(get_xn(samples,n))*2)\n",
        "    return(mag)\n",
        "mag = get_xns(__frames0[4])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "qKa6Pah3QEik",
        "outputId": "6677dc21-77ae-4725-cec2-467de1678199"
      },
      "source": [
        "## Fourier Plot \n",
        "\n",
        "def get_Hz_scale_vec(ks,sample_rate,Npoints):\n",
        "    freq_Hz = ks*sample_rate/Npoints\n",
        "    freq_Hz  = [int(i) for i in freq_Hz ] \n",
        "    return(freq_Hz )\n",
        "Nxlim = 12\n",
        "sample_rate = int(9600/4)             \n",
        "ks   = np.linspace(0,len(mag),Nxlim)\n",
        "ksHz = get_Hz_scale_vec(ks,sample_rate,len(__frames1[0]))\n",
        "\n",
        "plt.figure(figsize=(20,3))\n",
        "plt.plot(mag[1:])\n",
        "plt.xticks(ks,ksHz)\n",
        "plt.title(\"Frequency Domain\")\n",
        "plt.xlabel(\"Frequency (Hz)\")\n",
        "plt.ylabel(\"|Fourier Coefficient|\")\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "0OawIhlaWke4",
        "outputId": "40cac1f6-6d7e-48c0-dd3f-dd71d83bb56e"
      },
      "source": [
        "plt.plot (__label0[3])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f05525807d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJUw7uZnRSqS"
      },
      "source": [
        "## Fourier coefficients of label0 \n",
        "__fourier0 = np.zeros((__maxFrames,len(mag)))\n",
        "for i in range(0, __maxFrames):\n",
        "  __fourier0[i] = np.array(get_xns(__label0[i]))\n",
        "\n",
        "\n",
        "\n",
        "## Fourier coefficients of label1 \n",
        "__fourier1 = np.zeros((__maxFrames,len(mag)))\n",
        "for i in range(0, __maxFrames):\n",
        "  __fourier1[i] = np.array(get_xns(__label1[i]))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CnpRw747nep",
        "outputId": "1cb0e8cb-2150-42c8-e29b-832c3337b97d"
      },
      "source": [
        "X = np.asarray(np.concatenate((__fourier0[:, 1:], __fourier1[:, 1:]), axis = 0), dtype=np.float32)\n",
        "Y = np.asarray(np.concatenate((Y0, Y1), axis = 0), dtype = np.float32)\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(214, 24)\n",
            "(214,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkru_rqG8y_j"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "X, Y = shuffle(X,Y)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlQZ0BlbVWLM",
        "outputId": "0a5fe5f3-3b97-41b7-ea76-5c74fc3a3579"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(214, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck0cKbVUZN0W"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ominAygc6Vy"
      },
      "source": [
        "sigma = 1.0 #Sigmoid parameter for tanh\n",
        "depth = 3 #Depth of Bonsai Tree\n",
        "projectionDimension = 28 #Lower Dimensional space for Bonsai to work on\n",
        "\n",
        "#Regularizers for Bonsai Parameters\n",
        "regZ = 0.0001\n",
        "regW = 0.001\n",
        "regV = 0.001\n",
        "regT = 0.001\n",
        "\n",
        "totalEpochs = 600\n",
        "\n",
        "learningRate = 0.01\n",
        "\n",
        "outFile = None\n",
        "\n",
        "#Sparsity for Bonsai Parameters. x => 100*x % are non-zeros\n",
        "sparZ = 0.2\n",
        "sparW = 0.3\n",
        "sparV = 0.3\n",
        "sparT = 0.62\n",
        "\n",
        "batchSize = np.maximum(100, int(np.ceil(np.sqrt(Ytrain.shape[0]))))\n",
        "\n",
        "useMCHLoss = True #only for Multiclass cases True: Multiclass-Hing Loss, False: Cross Entropy. \n",
        "\n",
        "#Bonsai uses one classier for Binary, thus this condition\n",
        "\n",
        "numClasses = 1"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2MRgV4gc-_s",
        "outputId": "8e925990-5095-472d-9fae-0a3c87d4a1e1"
      },
      "source": [
        "Xtrain.shape\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(143, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN67KxdgdACD"
      },
      "source": [
        "__X = tf.placeholder(\"float32\", [None, Xtrain.shape[1]])\n",
        "__Y = tf.placeholder(\"float32\", [None, numClasses])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkldZ0STdEPY",
        "outputId": "d002f711-2830-40fa-f202-fa957ddedd31"
      },
      "source": [
        "bonsaiObj = Bonsai(numClasses, Xtrain.shape[1], projectionDimension, depth, sigma)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /content/EdgeML/tf/edgeml_tf/graph/bonsai.py:70: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPBv2p91dL9Z",
        "outputId": "8217a8db-1f13-42ac-aa5a-3c14cc7d2462"
      },
      "source": [
        "bonsaiTrainer = BonsaiTrainer(bonsaiObj, regW, regT, regV, regZ, sparW, sparT, sparV, sparZ,\n",
        "                              learningRate, __X, __Y, useMCHLoss, outFile)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /content/EdgeML/tf/edgeml_tf/trainer/bonsaiTrainer.py:123: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/EdgeML/tf/edgeml_tf/trainer/bonsaiTrainer.py:142: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1c7ssxadNpI"
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--pIpr0idPMq",
        "outputId": "0141dbf2-ca65-45ed-c543-b38e7747fab6"
      },
      "source": [
        "Ytrain.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(143,)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36aFCHoydRnu"
      },
      "source": [
        "Ytrain = np.expand_dims(Ytrain,1)\n",
        "Ytest = np.expand_dims(Ytest,1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8_J78UUdVTp",
        "outputId": "c59b6623-a568-41ba-da27-0197106108a2"
      },
      "source": [
        "bonsaiTrainer.train(batchSize, totalEpochs, sess,\n",
        "                    Xtrain, Xtest, Ytrain, Ytest, '/content', '/content')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch Number: 0\n",
            "\n",
            "******************** Dense Training Phase Started ********************\n",
            "\n",
            "\n",
            "Classification Train Loss: 0.8331303596496582\n",
            "Training accuracy (Classification): 0.7099999785423279\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.8257654 + 0.20440209 = 1.0301675\n",
            "\n",
            "\n",
            "Epoch Number: 1\n",
            "\n",
            "Classification Train Loss: 0.8279882073402405\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.8279642 + 0.20323539 = 1.0311996\n",
            "\n",
            "\n",
            "Epoch Number: 2\n",
            "\n",
            "Classification Train Loss: 0.8232915997505188\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.82959414 + 0.20201086 = 1.031605\n",
            "\n",
            "\n",
            "Epoch Number: 3\n",
            "\n",
            "Classification Train Loss: 0.8188823461532593\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.82873964 + 0.20072746 = 1.0294671\n",
            "\n",
            "\n",
            "Epoch Number: 4\n",
            "\n",
            "Classification Train Loss: 0.8141602873802185\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.82617104 + 0.19939603 = 1.025567\n",
            "\n",
            "\n",
            "Epoch Number: 5\n",
            "\n",
            "Classification Train Loss: 0.8089232444763184\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.81979257 + 0.19801491 = 1.0178075\n",
            "\n",
            "\n",
            "Epoch Number: 6\n",
            "\n",
            "Classification Train Loss: 0.803260326385498\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.81275797 + 0.19661847 = 1.0093764\n",
            "\n",
            "\n",
            "Epoch Number: 7\n",
            "\n",
            "Classification Train Loss: 0.7990678548812866\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.81012917 + 0.19522189 = 1.0053511\n",
            "\n",
            "\n",
            "Epoch Number: 8\n",
            "\n",
            "Classification Train Loss: 0.7954522967338562\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.8130927 + 0.19384024 = 1.006933\n",
            "\n",
            "\n",
            "Epoch Number: 9\n",
            "\n",
            "Classification Train Loss: 0.7900571823120117\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.8219691 + 0.19247764 = 1.0144467\n",
            "\n",
            "\n",
            "Epoch Number: 10\n",
            "\n",
            "Classification Train Loss: 0.7846742272377014\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.82907087 + 0.1910959 = 1.0201668\n",
            "\n",
            "\n",
            "Epoch Number: 11\n",
            "\n",
            "Classification Train Loss: 0.7812597155570984\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.8307963 + 0.18968911 = 1.0204854\n",
            "\n",
            "\n",
            "Epoch Number: 12\n",
            "\n",
            "Classification Train Loss: 0.7771432995796204\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.8287461 + 0.18825635 = 1.0170025\n",
            "\n",
            "\n",
            "Epoch Number: 13\n",
            "\n",
            "Classification Train Loss: 0.7731980085372925\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.82591295 + 0.18681441 = 1.0127274\n",
            "\n",
            "\n",
            "Epoch Number: 14\n",
            "\n",
            "Classification Train Loss: 0.7696758508682251\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.8283638 + 0.18540394 = 1.0137677\n",
            "\n",
            "\n",
            "Epoch Number: 15\n",
            "\n",
            "Classification Train Loss: 0.7662076354026794\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.8322764 + 0.18402046 = 1.0162969\n",
            "\n",
            "\n",
            "Epoch Number: 16\n",
            "\n",
            "Classification Train Loss: 0.7627716660499573\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.8360272 + 0.18265253 = 1.0186797\n",
            "\n",
            "\n",
            "Epoch Number: 17\n",
            "\n",
            "Classification Train Loss: 0.759375274181366\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.83961153 + 0.18130197 = 1.0209135\n",
            "\n",
            "\n",
            "Epoch Number: 18\n",
            "\n",
            "Classification Train Loss: 0.7562174797058105\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.840843 + 0.1799758 = 1.0208188\n",
            "\n",
            "\n",
            "Epoch Number: 19\n",
            "\n",
            "Classification Train Loss: 0.7527685761451721\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.83991706 + 0.17867514 = 1.0185922\n",
            "\n",
            "\n",
            "Epoch Number: 20\n",
            "\n",
            "Classification Train Loss: 0.7490239143371582\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.8370048 + 0.17740165 = 1.0144064\n",
            "\n",
            "\n",
            "Epoch Number: 21\n",
            "\n",
            "Classification Train Loss: 0.7463496923446655\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.84164524 + 0.1761793 = 1.0178245\n",
            "\n",
            "\n",
            "Epoch Number: 22\n",
            "\n",
            "Classification Train Loss: 0.7426266074180603\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.8517996 + 0.17499575 = 1.0267954\n",
            "\n",
            "\n",
            "Epoch Number: 23\n",
            "\n",
            "Classification Train Loss: 0.741361141204834\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.85063356 + 0.17380337 = 1.024437\n",
            "\n",
            "\n",
            "Epoch Number: 24\n",
            "\n",
            "Classification Train Loss: 0.7371522188186646\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.842844 + 0.17261411 = 1.0154581\n",
            "\n",
            "\n",
            "Epoch Number: 25\n",
            "\n",
            "Classification Train Loss: 0.7346947193145752\n",
            "Training accuracy (Classification): 0.7099999785423279\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.8427492 + 0.17146915 = 1.0142183\n",
            "\n",
            "\n",
            "Epoch Number: 26\n",
            "\n",
            "Classification Train Loss: 0.7333959341049194\n",
            "Training accuracy (Classification): 0.7099999785423279\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.8524703 + 0.17034677 = 1.022817\n",
            "\n",
            "\n",
            "Epoch Number: 27\n",
            "\n",
            "Classification Train Loss: 0.7283618450164795\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.86513436 + 0.16923317 = 1.0343676\n",
            "\n",
            "\n",
            "Epoch Number: 28\n",
            "\n",
            "Classification Train Loss: 0.7276540994644165\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.86663467 + 0.16812009 = 1.0347548\n",
            "\n",
            "\n",
            "Epoch Number: 29\n",
            "\n",
            "Classification Train Loss: 0.724412202835083\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.8612745 + 0.1670034 = 1.0282779\n",
            "\n",
            "\n",
            "Epoch Number: 30\n",
            "\n",
            "Classification Train Loss: 0.7217236757278442\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.86076045 + 0.16590224 = 1.0266627\n",
            "\n",
            "\n",
            "Epoch Number: 31\n",
            "\n",
            "Classification Train Loss: 0.7208330035209656\n",
            "Training accuracy (Classification): 0.699999988079071\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.8660493 + 0.16481912 = 1.0308684\n",
            "\n",
            "\n",
            "Epoch Number: 32\n",
            "\n",
            "Classification Train Loss: 0.7175683975219727\n",
            "Training accuracy (Classification): 0.7099999785423279\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.8767773 + 0.16375996 = 1.0405372\n",
            "\n",
            "\n",
            "Epoch Number: 33\n",
            "\n",
            "Classification Train Loss: 0.7143787145614624\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.8878464 + 0.16270776 = 1.0505542\n",
            "\n",
            "\n",
            "Epoch Number: 34\n",
            "\n",
            "Classification Train Loss: 0.7140634655952454\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.8872248 + 0.16164292 = 1.0488677\n",
            "\n",
            "\n",
            "Epoch Number: 35\n",
            "\n",
            "Classification Train Loss: 0.7097861766815186\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.8851104 + 0.16060448 = 1.0457149\n",
            "\n",
            "\n",
            "Epoch Number: 36\n",
            "\n",
            "Classification Train Loss: 0.7076687812805176\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.88649356 + 0.15958951 = 1.0460831\n",
            "\n",
            "\n",
            "Epoch Number: 37\n",
            "\n",
            "Classification Train Loss: 0.7060230374336243\n",
            "Training accuracy (Classification): 0.7099999785423279\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.89094764 + 0.15859002 = 1.0495377\n",
            "\n",
            "\n",
            "Epoch Number: 38\n",
            "\n",
            "Classification Train Loss: 0.7036195993423462\n",
            "Training accuracy (Classification): 0.7099999785423279\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.8981112 + 0.15760718 = 1.0557184\n",
            "\n",
            "\n",
            "Epoch Number: 39\n",
            "\n",
            "Classification Train Loss: 0.7007819414138794\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.90511703 + 0.15662707 = 1.0617441\n",
            "\n",
            "\n",
            "Epoch Number: 40\n",
            "\n",
            "Classification Train Loss: 0.6986334919929504\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9117011 + 0.15565172 = 1.0673528\n",
            "\n",
            "\n",
            "Epoch Number: 41\n",
            "\n",
            "Classification Train Loss: 0.696765661239624\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9146743 + 0.1546595 = 1.0693338\n",
            "\n",
            "\n",
            "Epoch Number: 42\n",
            "\n",
            "Classification Train Loss: 0.6943347454071045\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9145975 + 0.15365517 = 1.0682527\n",
            "\n",
            "\n",
            "Epoch Number: 43\n",
            "\n",
            "Classification Train Loss: 0.6918604969978333\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9162546 + 0.15265803 = 1.0689126\n",
            "\n",
            "\n",
            "Epoch Number: 44\n",
            "\n",
            "Classification Train Loss: 0.6898999214172363\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.92023987 + 0.15168063 = 1.0719205\n",
            "\n",
            "\n",
            "Epoch Number: 45\n",
            "\n",
            "Classification Train Loss: 0.6875979900360107\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.9264934 + 0.15072359 = 1.077217\n",
            "\n",
            "\n",
            "Epoch Number: 46\n",
            "\n",
            "Classification Train Loss: 0.6851946115493774\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.9327862 + 0.14978424 = 1.0825704\n",
            "\n",
            "\n",
            "Epoch Number: 47\n",
            "\n",
            "Classification Train Loss: 0.6831719875335693\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.93688667 + 0.14886701 = 1.0857537\n",
            "\n",
            "\n",
            "Epoch Number: 48\n",
            "\n",
            "Classification Train Loss: 0.6810886859893799\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.93579245 + 0.14796612 = 1.0837586\n",
            "\n",
            "\n",
            "Epoch Number: 49\n",
            "\n",
            "Classification Train Loss: 0.6786967515945435\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.605634\n",
            "MarginLoss + RegLoss: 0.9384347 + 0.14709166 = 1.0855263\n",
            "\n",
            "\n",
            "Epoch Number: 50\n",
            "\n",
            "Classification Train Loss: 0.6772552728652954\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.94866276 + 0.14624724 = 1.09491\n",
            "\n",
            "\n",
            "Epoch Number: 51\n",
            "\n",
            "Classification Train Loss: 0.6752276420593262\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.94898164 + 0.14540756 = 1.0943892\n",
            "\n",
            "\n",
            "Epoch Number: 52\n",
            "\n",
            "Classification Train Loss: 0.6725377440452576\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.591549\n",
            "MarginLoss + RegLoss: 0.94941723 + 0.14456463 = 1.0939819\n",
            "\n",
            "\n",
            "Epoch Number: 53\n",
            "\n",
            "Classification Train Loss: 0.6718432903289795\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.9573259 + 0.14375107 = 1.101077\n",
            "\n",
            "\n",
            "Epoch Number: 54\n",
            "\n",
            "Classification Train Loss: 0.6694135665893555\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.96149015 + 0.14294718 = 1.1044374\n",
            "\n",
            "\n",
            "Epoch Number: 55\n",
            "\n",
            "Classification Train Loss: 0.6682453751564026\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.605634\n",
            "MarginLoss + RegLoss: 0.95622736 + 0.14213306 = 1.0983604\n",
            "\n",
            "\n",
            "Epoch Number: 56\n",
            "\n",
            "Classification Train Loss: 0.6690447926521301\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.9598321 + 0.14134157 = 1.1011736\n",
            "\n",
            "\n",
            "Epoch Number: 57\n",
            "\n",
            "Classification Train Loss: 0.6663090586662292\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.9709261 + 0.1405627 = 1.1114888\n",
            "\n",
            "\n",
            "Epoch Number: 58\n",
            "\n",
            "Classification Train Loss: 0.6674795150756836\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.9621567 + 0.13976641 = 1.1019231\n",
            "\n",
            "\n",
            "Epoch Number: 59\n",
            "\n",
            "Classification Train Loss: 0.6632388234138489\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.96165687 + 0.13898714 = 1.100644\n",
            "\n",
            "\n",
            "Epoch Number: 60\n",
            "\n",
            "Classification Train Loss: 0.6626760363578796\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.96982926 + 0.1382386 = 1.1080679\n",
            "\n",
            "\n",
            "Epoch Number: 61\n",
            "\n",
            "Classification Train Loss: 0.661644697189331\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9656919 + 0.13746679 = 1.1031587\n",
            "\n",
            "\n",
            "Epoch Number: 62\n",
            "\n",
            "Classification Train Loss: 0.6582189798355103\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.95840126 + 0.13670486 = 1.0951061\n",
            "\n",
            "\n",
            "Epoch Number: 63\n",
            "\n",
            "Classification Train Loss: 0.6610291004180908\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9625813 + 0.13598396 = 1.0985652\n",
            "\n",
            "\n",
            "Epoch Number: 64\n",
            "\n",
            "Classification Train Loss: 0.6557766795158386\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9721963 + 0.13529126 = 1.1074876\n",
            "\n",
            "\n",
            "Epoch Number: 65\n",
            "\n",
            "Classification Train Loss: 0.6609262824058533\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9647563 + 0.1345727 = 1.099329\n",
            "\n",
            "\n",
            "Epoch Number: 66\n",
            "\n",
            "Classification Train Loss: 0.6536601781845093\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.95453787 + 0.13387308 = 1.088411\n",
            "\n",
            "\n",
            "Epoch Number: 67\n",
            "\n",
            "Classification Train Loss: 0.6585134267807007\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9580724 + 0.13322149 = 1.0912939\n",
            "\n",
            "\n",
            "Epoch Number: 68\n",
            "\n",
            "Classification Train Loss: 0.6525649428367615\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.96900594 + 0.13260815 = 1.1016141\n",
            "\n",
            "\n",
            "Epoch Number: 69\n",
            "\n",
            "Classification Train Loss: 0.6540852785110474\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9668039 + 0.13195595 = 1.0987599\n",
            "\n",
            "\n",
            "Epoch Number: 70\n",
            "\n",
            "Classification Train Loss: 0.6514849662780762\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.95678675 + 0.13128129 = 1.088068\n",
            "\n",
            "\n",
            "Epoch Number: 71\n",
            "\n",
            "Classification Train Loss: 0.6494090557098389\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.95337147 + 0.13063748 = 1.0840089\n",
            "\n",
            "\n",
            "Epoch Number: 72\n",
            "\n",
            "Classification Train Loss: 0.6514655351638794\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.96039665 + 0.13002816 = 1.0904248\n",
            "\n",
            "\n",
            "Epoch Number: 73\n",
            "\n",
            "Classification Train Loss: 0.6462428569793701\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9659487 + 0.12941636 = 1.095365\n",
            "\n",
            "\n",
            "Epoch Number: 74\n",
            "\n",
            "Classification Train Loss: 0.6473360061645508\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.96489596 + 0.12879288 = 1.0936888\n",
            "\n",
            "\n",
            "Epoch Number: 75\n",
            "\n",
            "Classification Train Loss: 0.6456099152565002\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.95924914 + 0.12815413 = 1.0874033\n",
            "\n",
            "\n",
            "Epoch Number: 76\n",
            "\n",
            "Classification Train Loss: 0.6433475017547607\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9549947 + 0.12753357 = 1.0825282\n",
            "\n",
            "\n",
            "Epoch Number: 77\n",
            "\n",
            "Classification Train Loss: 0.6448001861572266\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.95809376 + 0.12693572 = 1.0850295\n",
            "\n",
            "\n",
            "Epoch Number: 78\n",
            "\n",
            "Classification Train Loss: 0.6421387195587158\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.96539164 + 0.12637305 = 1.0917647\n",
            "\n",
            "\n",
            "Epoch Number: 79\n",
            "\n",
            "Classification Train Loss: 0.6407570242881775\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.97001153 + 0.12579735 = 1.0958089\n",
            "\n",
            "\n",
            "Epoch Number: 80\n",
            "\n",
            "Classification Train Loss: 0.6416544318199158\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9641601 + 0.12520102 = 1.0893611\n",
            "\n",
            "\n",
            "Epoch Number: 81\n",
            "\n",
            "Classification Train Loss: 0.6382393836975098\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.96061915 + 0.124624565 = 1.0852437\n",
            "\n",
            "\n",
            "Epoch Number: 82\n",
            "\n",
            "Classification Train Loss: 0.6384190917015076\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9616638 + 0.12408571 = 1.0857495\n",
            "\n",
            "\n",
            "Epoch Number: 83\n",
            "\n",
            "Classification Train Loss: 0.6374282836914062\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9672716 + 0.12358193 = 1.0908536\n",
            "\n",
            "\n",
            "Epoch Number: 84\n",
            "\n",
            "Classification Train Loss: 0.6352829337120056\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.973921 + 0.12309235 = 1.0970134\n",
            "\n",
            "\n",
            "Epoch Number: 85\n",
            "\n",
            "Classification Train Loss: 0.6357895135879517\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9697349 + 0.12257848 = 1.0923134\n",
            "\n",
            "\n",
            "Epoch Number: 86\n",
            "\n",
            "Classification Train Loss: 0.6332741975784302\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.966987 + 0.122082084 = 1.0890691\n",
            "\n",
            "\n",
            "Epoch Number: 87\n",
            "\n",
            "Classification Train Loss: 0.6333479881286621\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.96971273 + 0.12162171 = 1.0913345\n",
            "\n",
            "\n",
            "Epoch Number: 88\n",
            "\n",
            "Classification Train Loss: 0.6319682598114014\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.97653735 + 0.12120304 = 1.0977404\n",
            "\n",
            "\n",
            "Epoch Number: 89\n",
            "\n",
            "Classification Train Loss: 0.6303908228874207\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9781359 + 0.12078222 = 1.0989181\n",
            "\n",
            "\n",
            "Epoch Number: 90\n",
            "\n",
            "Classification Train Loss: 0.6293646693229675\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.977691 + 0.12036485 = 1.0980558\n",
            "\n",
            "\n",
            "Epoch Number: 91\n",
            "\n",
            "Classification Train Loss: 0.6284011006355286\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9785696 + 0.119960755 = 1.0985304\n",
            "\n",
            "\n",
            "Epoch Number: 92\n",
            "\n",
            "Classification Train Loss: 0.6277292966842651\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9857619 + 0.11956456 = 1.1053264\n",
            "\n",
            "\n",
            "Epoch Number: 93\n",
            "\n",
            "Classification Train Loss: 0.6274137496948242\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9824738 + 0.11914356 = 1.1016173\n",
            "\n",
            "\n",
            "Epoch Number: 94\n",
            "\n",
            "Classification Train Loss: 0.6257893443107605\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9859436 + 0.11873454 = 1.1046782\n",
            "\n",
            "\n",
            "Epoch Number: 95\n",
            "\n",
            "Classification Train Loss: 0.6243882179260254\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.99116755 + 0.118335105 = 1.1095027\n",
            "\n",
            "\n",
            "Epoch Number: 96\n",
            "\n",
            "Classification Train Loss: 0.624984860420227\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.98496187 + 0.11791028 = 1.1028721\n",
            "\n",
            "\n",
            "Epoch Number: 97\n",
            "\n",
            "Classification Train Loss: 0.6246213912963867\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.99139297 + 0.11752833 = 1.1089213\n",
            "\n",
            "\n",
            "Epoch Number: 98\n",
            "\n",
            "Classification Train Loss: 0.6215225458145142\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.99529713 + 0.1171549 = 1.112452\n",
            "\n",
            "\n",
            "Epoch Number: 99\n",
            "\n",
            "Classification Train Loss: 0.6218100190162659\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.987879 + 0.11675652 = 1.1046355\n",
            "\n",
            "\n",
            "Epoch Number: 100\n",
            "\n",
            "Classification Train Loss: 0.6308767795562744\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.97480434 + 0.116236635 = 1.091041\n",
            "\n",
            "\n",
            "Epoch Number: 101\n",
            "\n",
            "Classification Train Loss: 0.6368021965026855\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9770266 + 0.11576059 = 1.0927871\n",
            "\n",
            "\n",
            "Epoch Number: 102\n",
            "\n",
            "Classification Train Loss: 0.6308055520057678\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.9875105 + 0.11526612 = 1.1027766\n",
            "\n",
            "\n",
            "Epoch Number: 103\n",
            "\n",
            "Classification Train Loss: 0.6289976239204407\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.9829149 + 0.114668876 = 1.0975838\n",
            "\n",
            "\n",
            "Epoch Number: 104\n",
            "\n",
            "Classification Train Loss: 0.6256699562072754\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9692127 + 0.11398748 = 1.0832002\n",
            "\n",
            "\n",
            "Epoch Number: 105\n",
            "\n",
            "Classification Train Loss: 0.6260507106781006\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.96657264 + 0.11334053 = 1.0799131\n",
            "\n",
            "\n",
            "Epoch Number: 106\n",
            "\n",
            "Classification Train Loss: 0.6229562759399414\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9733146 + 0.11271342 = 1.086028\n",
            "\n",
            "\n",
            "Epoch Number: 107\n",
            "\n",
            "Classification Train Loss: 0.6222853660583496\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9640566 + 0.11202337 = 1.07608\n",
            "\n",
            "\n",
            "Epoch Number: 108\n",
            "\n",
            "Classification Train Loss: 0.6168087720870972\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.95323646 + 0.11133835 = 1.0645748\n",
            "\n",
            "\n",
            "Epoch Number: 109\n",
            "\n",
            "Classification Train Loss: 0.6212657690048218\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9600105 + 0.11075629 = 1.0707668\n",
            "\n",
            "\n",
            "Epoch Number: 110\n",
            "\n",
            "Classification Train Loss: 0.6166133284568787\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.95831597 + 0.11016095 = 1.0684769\n",
            "\n",
            "\n",
            "Epoch Number: 111\n",
            "\n",
            "Classification Train Loss: 0.6164351105690002\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.94871426 + 0.109555736 = 1.05827\n",
            "\n",
            "\n",
            "Epoch Number: 112\n",
            "\n",
            "Classification Train Loss: 0.6152288913726807\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.94893736 + 0.10903806 = 1.0579754\n",
            "\n",
            "\n",
            "Epoch Number: 113\n",
            "\n",
            "Classification Train Loss: 0.6137881278991699\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.95445085 + 0.10857114 = 1.063022\n",
            "\n",
            "\n",
            "Epoch Number: 114\n",
            "\n",
            "Classification Train Loss: 0.6143131256103516\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.95511204 + 0.10812123 = 1.0632333\n",
            "\n",
            "\n",
            "Epoch Number: 115\n",
            "\n",
            "Classification Train Loss: 0.613716185092926\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.95089144 + 0.107688256 = 1.0585797\n",
            "\n",
            "\n",
            "Epoch Number: 116\n",
            "\n",
            "Classification Train Loss: 0.611473023891449\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9459249 + 0.107284516 = 1.0532094\n",
            "\n",
            "\n",
            "Epoch Number: 117\n",
            "\n",
            "Classification Train Loss: 0.6152249574661255\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.95615417 + 0.106985405 = 1.0631396\n",
            "\n",
            "\n",
            "Epoch Number: 118\n",
            "\n",
            "Classification Train Loss: 0.6104045510292053\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.96530575 + 0.10670357 = 1.0720093\n",
            "\n",
            "\n",
            "Epoch Number: 119\n",
            "\n",
            "Classification Train Loss: 0.61443692445755\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.95929635 + 0.10636684 = 1.0656632\n",
            "\n",
            "\n",
            "Epoch Number: 120\n",
            "\n",
            "Classification Train Loss: 0.6085469722747803\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9540589 + 0.106054544 = 1.0601134\n",
            "\n",
            "\n",
            "Epoch Number: 121\n",
            "\n",
            "Classification Train Loss: 0.6101053953170776\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.96010435 + 0.10580244 = 1.0659068\n",
            "\n",
            "\n",
            "Epoch Number: 122\n",
            "\n",
            "Classification Train Loss: 0.6064605712890625\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.96947956 + 0.10557113 = 1.0750507\n",
            "\n",
            "\n",
            "Epoch Number: 123\n",
            "\n",
            "Classification Train Loss: 0.608780026435852\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9676697 + 0.10529673 = 1.0729665\n",
            "\n",
            "\n",
            "Epoch Number: 124\n",
            "\n",
            "Classification Train Loss: 0.6053577661514282\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.96324307 + 0.105024874 = 1.068268\n",
            "\n",
            "\n",
            "Epoch Number: 125\n",
            "\n",
            "Classification Train Loss: 0.6068615913391113\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9667822 + 0.10478865 = 1.0715709\n",
            "\n",
            "\n",
            "Epoch Number: 126\n",
            "\n",
            "Classification Train Loss: 0.6050204634666443\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9771817 + 0.10457312 = 1.0817548\n",
            "\n",
            "\n",
            "Epoch Number: 127\n",
            "\n",
            "Classification Train Loss: 0.6053342223167419\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9772749 + 0.10431745 = 1.0815923\n",
            "\n",
            "\n",
            "Epoch Number: 128\n",
            "\n",
            "Classification Train Loss: 0.603097677230835\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9697027 + 0.104029514 = 1.0737323\n",
            "\n",
            "\n",
            "Epoch Number: 129\n",
            "\n",
            "Classification Train Loss: 0.6071609258651733\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9746032 + 0.10381004 = 1.0784132\n",
            "\n",
            "\n",
            "Epoch Number: 130\n",
            "\n",
            "Classification Train Loss: 0.602387547492981\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9877377 + 0.103613175 = 1.0913509\n",
            "\n",
            "\n",
            "Epoch Number: 131\n",
            "\n",
            "Classification Train Loss: 0.6048331260681152\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.98843676 + 0.103364155 = 1.0918009\n",
            "\n",
            "\n",
            "Epoch Number: 132\n",
            "\n",
            "Classification Train Loss: 0.6032006740570068\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.97804135 + 0.10307176 = 1.0811131\n",
            "\n",
            "\n",
            "Epoch Number: 133\n",
            "\n",
            "Classification Train Loss: 0.601715087890625\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.98025876 + 0.10283656 = 1.0830953\n",
            "\n",
            "\n",
            "Epoch Number: 134\n",
            "\n",
            "Classification Train Loss: 0.6007345914840698\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9898497 + 0.10265173 = 1.0925014\n",
            "\n",
            "\n",
            "Epoch Number: 135\n",
            "\n",
            "Classification Train Loss: 0.5986674427986145\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9937242 + 0.10246539 = 1.0961896\n",
            "\n",
            "\n",
            "Epoch Number: 136\n",
            "\n",
            "Classification Train Loss: 0.5989772081375122\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9891306 + 0.1022539 = 1.0913845\n",
            "\n",
            "\n",
            "Epoch Number: 137\n",
            "\n",
            "Classification Train Loss: 0.597879946231842\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9898025 + 0.102080815 = 1.0918833\n",
            "\n",
            "\n",
            "Epoch Number: 138\n",
            "\n",
            "Classification Train Loss: 0.5976929664611816\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9955508 + 0.10193688 = 1.0974877\n",
            "\n",
            "\n",
            "Epoch Number: 139\n",
            "\n",
            "Classification Train Loss: 0.5960228443145752\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.0017483 + 0.10179363 = 1.103542\n",
            "\n",
            "\n",
            "Epoch Number: 140\n",
            "\n",
            "Classification Train Loss: 0.5974377989768982\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9949312 + 0.10160091 = 1.0965321\n",
            "\n",
            "\n",
            "Epoch Number: 141\n",
            "\n",
            "Classification Train Loss: 0.5956195592880249\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9936184 + 0.10143261 = 1.095051\n",
            "\n",
            "\n",
            "Epoch Number: 142\n",
            "\n",
            "Classification Train Loss: 0.5965744256973267\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.005241 + 0.10129763 = 1.1065387\n",
            "\n",
            "\n",
            "Epoch Number: 143\n",
            "\n",
            "Classification Train Loss: 0.5956167578697205\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.0045233 + 0.1011078 = 1.1056311\n",
            "\n",
            "\n",
            "Epoch Number: 144\n",
            "\n",
            "Classification Train Loss: 0.5939193964004517\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.9933156 + 0.10087153 = 1.0941871\n",
            "\n",
            "\n",
            "Epoch Number: 145\n",
            "\n",
            "Classification Train Loss: 0.5985995531082153\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99894243 + 0.100704715 = 1.0996472\n",
            "\n",
            "\n",
            "Epoch Number: 146\n",
            "\n",
            "Classification Train Loss: 0.5925458669662476\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.009546 + 0.10056309 = 1.1101091\n",
            "\n",
            "\n",
            "Epoch Number: 147\n",
            "\n",
            "Classification Train Loss: 0.5949904322624207\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0052598 + 0.100379325 = 1.1056391\n",
            "\n",
            "\n",
            "Epoch Number: 148\n",
            "\n",
            "Classification Train Loss: 0.5907876491546631\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9975844 + 0.10019846 = 1.0977829\n",
            "\n",
            "\n",
            "Epoch Number: 149\n",
            "\n",
            "Classification Train Loss: 0.5935031771659851\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.005908 + 0.10008508 = 1.105993\n",
            "\n",
            "\n",
            "Epoch Number: 150\n",
            "\n",
            "Classification Train Loss: 0.5895301699638367\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.0121405 + 0.09997323 = 1.1121137\n",
            "\n",
            "\n",
            "Epoch Number: 151\n",
            "\n",
            "Classification Train Loss: 0.5929006934165955\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0039712 + 0.099819265 = 1.1037905\n",
            "\n",
            "\n",
            "Epoch Number: 152\n",
            "\n",
            "Classification Train Loss: 0.5891644358634949\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0027636 + 0.09968771 = 1.1024513\n",
            "\n",
            "\n",
            "Epoch Number: 153\n",
            "\n",
            "Classification Train Loss: 0.5898516774177551\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.010267 + 0.09958191 = 1.109849\n",
            "\n",
            "\n",
            "Epoch Number: 154\n",
            "\n",
            "Classification Train Loss: 0.5876575708389282\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0100582 + 0.09946211 = 1.1095203\n",
            "\n",
            "\n",
            "Epoch Number: 155\n",
            "\n",
            "Classification Train Loss: 0.586907684803009\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0107678 + 0.09935411 = 1.110122\n",
            "\n",
            "\n",
            "Epoch Number: 156\n",
            "\n",
            "Classification Train Loss: 0.586357831954956\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0130711 + 0.09925146 = 1.1123226\n",
            "\n",
            "\n",
            "Epoch Number: 157\n",
            "\n",
            "Classification Train Loss: 0.58560711145401\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0160767 + 0.099160574 = 1.1152372\n",
            "\n",
            "\n",
            "Epoch Number: 158\n",
            "\n",
            "Classification Train Loss: 0.5851060152053833\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0128759 + 0.099051125 = 1.111927\n",
            "\n",
            "\n",
            "Epoch Number: 159\n",
            "\n",
            "Classification Train Loss: 0.5865740180015564\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.0229915 + 0.098982915 = 1.1219745\n",
            "\n",
            "\n",
            "Epoch Number: 160\n",
            "\n",
            "Classification Train Loss: 0.5859951376914978\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0189384 + 0.09886882 = 1.1178073\n",
            "\n",
            "\n",
            "Epoch Number: 161\n",
            "\n",
            "Classification Train Loss: 0.5839945077896118\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0241212 + 0.09877156 = 1.1228927\n",
            "\n",
            "\n",
            "Epoch Number: 162\n",
            "\n",
            "Classification Train Loss: 0.583405613899231\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0219764 + 0.09866248 = 1.1206388\n",
            "\n",
            "\n",
            "Epoch Number: 163\n",
            "\n",
            "Classification Train Loss: 0.5831246972084045\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0293009 + 0.09858428 = 1.1278852\n",
            "\n",
            "\n",
            "Epoch Number: 164\n",
            "\n",
            "Classification Train Loss: 0.5834761261940002\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0256131 + 0.09848654 = 1.1240996\n",
            "\n",
            "\n",
            "Epoch Number: 165\n",
            "\n",
            "Classification Train Loss: 0.5819138884544373\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0254143 + 0.098405 = 1.1238194\n",
            "\n",
            "\n",
            "Epoch Number: 166\n",
            "\n",
            "Classification Train Loss: 0.58245849609375\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0397285 + 0.098368205 = 1.1380967\n",
            "\n",
            "\n",
            "Epoch Number: 167\n",
            "\n",
            "Classification Train Loss: 0.5863882899284363\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.036442 + 0.09829271 = 1.1347347\n",
            "\n",
            "\n",
            "Epoch Number: 168\n",
            "\n",
            "Classification Train Loss: 0.5818844437599182\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0220833 + 0.098191634 = 1.1202749\n",
            "\n",
            "\n",
            "Epoch Number: 169\n",
            "\n",
            "Classification Train Loss: 0.5909419059753418\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0273647 + 0.09815787 = 1.1255226\n",
            "\n",
            "\n",
            "Epoch Number: 170\n",
            "\n",
            "Classification Train Loss: 0.5845955014228821\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0541679 + 0.0981812 = 1.1523491\n",
            "\n",
            "\n",
            "Epoch Number: 171\n",
            "\n",
            "Classification Train Loss: 0.5912911295890808\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.0590476 + 0.09814206 = 1.1571896\n",
            "\n",
            "\n",
            "Epoch Number: 172\n",
            "\n",
            "Classification Train Loss: 0.5942736864089966\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0407774 + 0.098047435 = 1.1388249\n",
            "\n",
            "\n",
            "Epoch Number: 173\n",
            "\n",
            "Classification Train Loss: 0.5778982639312744\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0232862 + 0.09795291 = 1.1212392\n",
            "\n",
            "\n",
            "Epoch Number: 174\n",
            "\n",
            "Classification Train Loss: 0.5954751372337341\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0295349 + 0.097937495 = 1.1274724\n",
            "\n",
            "\n",
            "Epoch Number: 175\n",
            "\n",
            "Classification Train Loss: 0.5859813690185547\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.0572063 + 0.097982354 = 1.1551887\n",
            "\n",
            "\n",
            "Epoch Number: 176\n",
            "\n",
            "Classification Train Loss: 0.586305558681488\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.0662853 + 0.097980514 = 1.1642658\n",
            "\n",
            "\n",
            "Epoch Number: 177\n",
            "\n",
            "Classification Train Loss: 0.5934471487998962\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0523334 + 0.09792267 = 1.150256\n",
            "\n",
            "\n",
            "Epoch Number: 178\n",
            "\n",
            "Classification Train Loss: 0.5795395374298096\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0275832 + 0.09783562 = 1.1254189\n",
            "\n",
            "\n",
            "Epoch Number: 179\n",
            "\n",
            "Classification Train Loss: 0.5925467014312744\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0259539 + 0.09781195 = 1.1237658\n",
            "\n",
            "\n",
            "Epoch Number: 180\n",
            "\n",
            "Classification Train Loss: 0.596197247505188\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0423163 + 0.09784854 = 1.1401649\n",
            "\n",
            "\n",
            "Epoch Number: 181\n",
            "\n",
            "Classification Train Loss: 0.5758852362632751\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 1.0756395 + 0.097894944 = 1.1735344\n",
            "\n",
            "\n",
            "Epoch Number: 182\n",
            "\n",
            "Classification Train Loss: 0.5955946445465088\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 1.0833768 + 0.0978744 = 1.1812512\n",
            "\n",
            "\n",
            "Epoch Number: 183\n",
            "\n",
            "Classification Train Loss: 0.6017757654190063\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.0658215 + 0.09778895 = 1.1636105\n",
            "\n",
            "\n",
            "Epoch Number: 184\n",
            "\n",
            "Classification Train Loss: 0.5839594602584839\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.034763 + 0.09768092 = 1.1324439\n",
            "\n",
            "\n",
            "Epoch Number: 185\n",
            "\n",
            "Classification Train Loss: 0.5824801325798035\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0265362 + 0.0976195 = 1.1241558\n",
            "\n",
            "\n",
            "Epoch Number: 186\n",
            "\n",
            "Classification Train Loss: 0.5963996052742004\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0366294 + 0.09762782 = 1.1342573\n",
            "\n",
            "\n",
            "Epoch Number: 187\n",
            "\n",
            "Classification Train Loss: 0.5794236660003662\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.064452 + 0.09765866 = 1.1621107\n",
            "\n",
            "\n",
            "Epoch Number: 188\n",
            "\n",
            "Classification Train Loss: 0.5791932344436646\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 1.072357 + 0.097659774 = 1.1700169\n",
            "\n",
            "\n",
            "Epoch Number: 189\n",
            "\n",
            "Classification Train Loss: 0.5857738852500916\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.0610595 + 0.097628355 = 1.1586878\n",
            "\n",
            "\n",
            "Epoch Number: 190\n",
            "\n",
            "Classification Train Loss: 0.5750914812088013\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.0411956 + 0.097594365 = 1.13879\n",
            "\n",
            "\n",
            "Epoch Number: 191\n",
            "\n",
            "Classification Train Loss: 0.5750632882118225\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0366237 + 0.097584546 = 1.1342082\n",
            "\n",
            "\n",
            "Epoch Number: 192\n",
            "\n",
            "Classification Train Loss: 0.5799663066864014\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 1.0467154 + 0.09760886 = 1.1443242\n",
            "\n",
            "\n",
            "Epoch Number: 193\n",
            "\n",
            "Classification Train Loss: 0.5727075338363647\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 1.0624766 + 0.09765743 = 1.1601341\n",
            "\n",
            "\n",
            "Epoch Number: 194\n",
            "\n",
            "Classification Train Loss: 0.5722254514694214\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.070096 + 0.097705305 = 1.1678014\n",
            "\n",
            "\n",
            "Epoch Number: 195\n",
            "\n",
            "Classification Train Loss: 0.5744080543518066\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 1.0647761 + 0.09774615 = 1.1625222\n",
            "\n",
            "\n",
            "Epoch Number: 196\n",
            "\n",
            "Classification Train Loss: 0.5704643726348877\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 1.0568061 + 0.09779817 = 1.1546042\n",
            "\n",
            "\n",
            "Epoch Number: 197\n",
            "\n",
            "Classification Train Loss: 0.5700386762619019\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.0553256 + 0.097874805 = 1.1532004\n",
            "\n",
            "\n",
            "Epoch Number: 198\n",
            "\n",
            "Classification Train Loss: 0.571168065071106\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 1.0628351 + 0.09795327 = 1.1607884\n",
            "\n",
            "\n",
            "Epoch Number: 199\n",
            "\n",
            "Classification Train Loss: 0.5685762166976929\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 1.0760771 + 0.098046504 = 1.1741236\n",
            "\n",
            "\n",
            "Epoch Number: 200\n",
            "\n",
            "Classification Train Loss: 0.6292736530303955\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.0568299 + 0.097966194 = 1.1547961\n",
            "\n",
            "\n",
            "Epoch Number: 201\n",
            "\n",
            "Classification Train Loss: 0.6044102907180786\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.605634\n",
            "MarginLoss + RegLoss: 1.0353497 + 0.097768925 = 1.1331186\n",
            "\n",
            "\n",
            "Epoch Number: 202\n",
            "\n",
            "Classification Train Loss: 0.6088163256645203\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.605634\n",
            "MarginLoss + RegLoss: 1.0288234 + 0.09756075 = 1.1263841\n",
            "\n",
            "\n",
            "Epoch Number: 203\n",
            "\n",
            "Classification Train Loss: 0.6219298243522644\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.605634\n",
            "MarginLoss + RegLoss: 1.0268662 + 0.09734163 = 1.1242079\n",
            "\n",
            "\n",
            "Epoch Number: 204\n",
            "\n",
            "Classification Train Loss: 0.6181241273880005\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.605634\n",
            "MarginLoss + RegLoss: 1.0290933 + 0.09710687 = 1.1262001\n",
            "\n",
            "\n",
            "Epoch Number: 205\n",
            "\n",
            "Classification Train Loss: 0.6014090180397034\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.0450091 + 0.09687325 = 1.1418824\n",
            "\n",
            "\n",
            "Epoch Number: 206\n",
            "\n",
            "Classification Train Loss: 0.6010102033615112\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 1.0505488 + 0.09654236 = 1.1470912\n",
            "\n",
            "\n",
            "Epoch Number: 207\n",
            "\n",
            "Classification Train Loss: 0.6140440702438354\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.0335424 + 0.09612366 = 1.1296661\n",
            "\n",
            "\n",
            "Epoch Number: 208\n",
            "\n",
            "Classification Train Loss: 0.597909152507782\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 1.0083307 + 0.09563721 = 1.1039679\n",
            "\n",
            "\n",
            "Epoch Number: 209\n",
            "\n",
            "Classification Train Loss: 0.5926401019096375\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.605634\n",
            "MarginLoss + RegLoss: 0.9968453 + 0.09519239 = 1.0920377\n",
            "\n",
            "\n",
            "Epoch Number: 210\n",
            "\n",
            "Classification Train Loss: 0.6013909578323364\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.605634\n",
            "MarginLoss + RegLoss: 0.99042016 + 0.09477409 = 1.0851942\n",
            "\n",
            "\n",
            "Epoch Number: 211\n",
            "\n",
            "Classification Train Loss: 0.5990399122238159\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.99021226 + 0.094400086 = 1.0846124\n",
            "\n",
            "\n",
            "Epoch Number: 212\n",
            "\n",
            "Classification Train Loss: 0.5876798033714294\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.99928635 + 0.0940593 = 1.0933456\n",
            "\n",
            "\n",
            "Epoch Number: 213\n",
            "\n",
            "Classification Train Loss: 0.590283215045929\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9942659 + 0.09365798 = 1.0879239\n",
            "\n",
            "\n",
            "Epoch Number: 214\n",
            "\n",
            "Classification Train Loss: 0.5912913680076599\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.97706753 + 0.09321268 = 1.0702802\n",
            "\n",
            "\n",
            "Epoch Number: 215\n",
            "\n",
            "Classification Train Loss: 0.5824278593063354\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.96398747 + 0.09279309 = 1.0567806\n",
            "\n",
            "\n",
            "Epoch Number: 216\n",
            "\n",
            "Classification Train Loss: 0.5863354206085205\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.9592551 + 0.0924423 = 1.0516974\n",
            "\n",
            "\n",
            "Epoch Number: 217\n",
            "\n",
            "Classification Train Loss: 0.5859587788581848\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.96198237 + 0.092153095 = 1.0541354\n",
            "\n",
            "\n",
            "Epoch Number: 218\n",
            "\n",
            "Classification Train Loss: 0.5811215043067932\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.96604294 + 0.09189181 = 1.0579348\n",
            "\n",
            "\n",
            "Epoch Number: 219\n",
            "\n",
            "Classification Train Loss: 0.5848948359489441\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.9638715 + 0.09161987 = 1.0554913\n",
            "\n",
            "\n",
            "Epoch Number: 220\n",
            "\n",
            "Classification Train Loss: 0.585332453250885\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9554429 + 0.091338284 = 1.0467812\n",
            "\n",
            "\n",
            "Epoch Number: 221\n",
            "\n",
            "Classification Train Loss: 0.5812919735908508\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.94542265 + 0.09107986 = 1.0365025\n",
            "\n",
            "\n",
            "Epoch Number: 222\n",
            "\n",
            "Classification Train Loss: 0.5827891230583191\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.941981 + 0.0908633 = 1.0328443\n",
            "\n",
            "\n",
            "Epoch Number: 223\n",
            "\n",
            "Classification Train Loss: 0.5844637751579285\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.94694984 + 0.09071372 = 1.0376636\n",
            "\n",
            "\n",
            "Epoch Number: 224\n",
            "\n",
            "Classification Train Loss: 0.579831063747406\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9528064 + 0.09059851 = 1.0434049\n",
            "\n",
            "\n",
            "Epoch Number: 225\n",
            "\n",
            "Classification Train Loss: 0.5807777643203735\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.9554573 + 0.09048987 = 1.0459472\n",
            "\n",
            "\n",
            "Epoch Number: 226\n",
            "\n",
            "Classification Train Loss: 0.5814840793609619\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.95191574 + 0.09036568 = 1.0422814\n",
            "\n",
            "\n",
            "Epoch Number: 227\n",
            "\n",
            "Classification Train Loss: 0.5786272287368774\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9485064 + 0.09025437 = 1.0387608\n",
            "\n",
            "\n",
            "Epoch Number: 228\n",
            "\n",
            "Classification Train Loss: 0.5777423977851868\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9471493 + 0.090164535 = 1.0373138\n",
            "\n",
            "\n",
            "Epoch Number: 229\n",
            "\n",
            "Classification Train Loss: 0.57912278175354\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.95212233 + 0.09011388 = 1.0422362\n",
            "\n",
            "\n",
            "Epoch Number: 230\n",
            "\n",
            "Classification Train Loss: 0.5764491558074951\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9573659 + 0.09006883 = 1.0474347\n",
            "\n",
            "\n",
            "Epoch Number: 231\n",
            "\n",
            "Classification Train Loss: 0.576218843460083\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.96193844 + 0.09003095 = 1.0519694\n",
            "\n",
            "\n",
            "Epoch Number: 232\n",
            "\n",
            "Classification Train Loss: 0.5769557356834412\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.95999885 + 0.089960195 = 1.0499591\n",
            "\n",
            "\n",
            "Epoch Number: 233\n",
            "\n",
            "Classification Train Loss: 0.5749619603157043\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9586216 + 0.08989772 = 1.0485194\n",
            "\n",
            "\n",
            "Epoch Number: 234\n",
            "\n",
            "Classification Train Loss: 0.5751305818557739\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9609333 + 0.08984544 = 1.0507787\n",
            "\n",
            "\n",
            "Epoch Number: 235\n",
            "\n",
            "Classification Train Loss: 0.5744137763977051\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9670591 + 0.08980315 = 1.0568622\n",
            "\n",
            "\n",
            "Epoch Number: 236\n",
            "\n",
            "Classification Train Loss: 0.5737048387527466\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9669806 + 0.08971454 = 1.0566951\n",
            "\n",
            "\n",
            "Epoch Number: 237\n",
            "\n",
            "Classification Train Loss: 0.5728701949119568\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9666664 + 0.08963759 = 1.056304\n",
            "\n",
            "\n",
            "Epoch Number: 238\n",
            "\n",
            "Classification Train Loss: 0.5726131796836853\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9678465 + 0.089576624 = 1.0574231\n",
            "\n",
            "\n",
            "Epoch Number: 239\n",
            "\n",
            "Classification Train Loss: 0.5722644329071045\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.97148055 + 0.08953124 = 1.0610118\n",
            "\n",
            "\n",
            "Epoch Number: 240\n",
            "\n",
            "Classification Train Loss: 0.5715382695198059\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9727155 + 0.089467876 = 1.0621834\n",
            "\n",
            "\n",
            "Epoch Number: 241\n",
            "\n",
            "Classification Train Loss: 0.5711713433265686\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9706975 + 0.08937658 = 1.0600741\n",
            "\n",
            "\n",
            "Epoch Number: 242\n",
            "\n",
            "Classification Train Loss: 0.5714693069458008\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.97485423 + 0.0893179 = 1.0641721\n",
            "\n",
            "\n",
            "Epoch Number: 243\n",
            "\n",
            "Classification Train Loss: 0.5708551406860352\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9724427 + 0.08921524 = 1.0616579\n",
            "\n",
            "\n",
            "Epoch Number: 244\n",
            "\n",
            "Classification Train Loss: 0.5703599452972412\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9762322 + 0.08914748 = 1.0653796\n",
            "\n",
            "\n",
            "Epoch Number: 245\n",
            "\n",
            "Classification Train Loss: 0.570530891418457\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.973496 + 0.08903663 = 1.0625327\n",
            "\n",
            "\n",
            "Epoch Number: 246\n",
            "\n",
            "Classification Train Loss: 0.5692685842514038\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9748744 + 0.088951126 = 1.0638255\n",
            "\n",
            "\n",
            "Epoch Number: 247\n",
            "\n",
            "Classification Train Loss: 0.5687767267227173\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.97212476 + 0.08884474 = 1.0609695\n",
            "\n",
            "\n",
            "Epoch Number: 248\n",
            "\n",
            "Classification Train Loss: 0.5697231888771057\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9763948 + 0.08878531 = 1.0651801\n",
            "\n",
            "\n",
            "Epoch Number: 249\n",
            "\n",
            "Classification Train Loss: 0.5687446594238281\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.97430974 + 0.08868258 = 1.0629923\n",
            "\n",
            "\n",
            "Epoch Number: 250\n",
            "\n",
            "Classification Train Loss: 0.5677933096885681\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.97341484 + 0.0886106 = 1.0620254\n",
            "\n",
            "\n",
            "Epoch Number: 251\n",
            "\n",
            "Classification Train Loss: 0.5676413178443909\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9763388 + 0.08857183 = 1.0649107\n",
            "\n",
            "\n",
            "Epoch Number: 252\n",
            "\n",
            "Classification Train Loss: 0.5675795078277588\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9741078 + 0.08849878 = 1.0626066\n",
            "\n",
            "\n",
            "Epoch Number: 253\n",
            "\n",
            "Classification Train Loss: 0.5667648315429688\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9732956 + 0.08844443 = 1.06174\n",
            "\n",
            "\n",
            "Epoch Number: 254\n",
            "\n",
            "Classification Train Loss: 0.5667905211448669\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9784819 + 0.08843639 = 1.0669183\n",
            "\n",
            "\n",
            "Epoch Number: 255\n",
            "\n",
            "Classification Train Loss: 0.5677158832550049\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.97591025 + 0.08836884 = 1.0642791\n",
            "\n",
            "\n",
            "Epoch Number: 256\n",
            "\n",
            "Classification Train Loss: 0.5656936168670654\n",
            "Training accuracy (Classification): 0.8399999737739563\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.971195 + 0.088293344 = 1.0594883\n",
            "\n",
            "\n",
            "Epoch Number: 257\n",
            "\n",
            "Classification Train Loss: 0.5682085752487183\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9754214 + 0.0882747 = 1.0636961\n",
            "\n",
            "\n",
            "Epoch Number: 258\n",
            "\n",
            "Classification Train Loss: 0.5649420022964478\n",
            "Training accuracy (Classification): 0.8399999737739563\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.98039114 + 0.08827093 = 1.068662\n",
            "\n",
            "\n",
            "Epoch Number: 259\n",
            "\n",
            "Classification Train Loss: 0.5672571063041687\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.97761726 + 0.088206865 = 1.0658242\n",
            "\n",
            "\n",
            "Epoch Number: 260\n",
            "\n",
            "Classification Train Loss: 0.5647352933883667\n",
            "Training accuracy (Classification): 0.8399999737739563\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.97141826 + 0.088123806 = 1.0595421\n",
            "\n",
            "\n",
            "Epoch Number: 261\n",
            "\n",
            "Classification Train Loss: 0.5676571726799011\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.97432536 + 0.0880999 = 1.0624253\n",
            "\n",
            "\n",
            "Epoch Number: 262\n",
            "\n",
            "Classification Train Loss: 0.564946174621582\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9826968 + 0.08810399 = 1.0708008\n",
            "\n",
            "\n",
            "Epoch Number: 263\n",
            "\n",
            "Classification Train Loss: 0.5672076344490051\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.980699 + 0.08802372 = 1.0687227\n",
            "\n",
            "\n",
            "Epoch Number: 264\n",
            "\n",
            "Classification Train Loss: 0.5654355883598328\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.97276103 + 0.087902784 = 1.0606638\n",
            "\n",
            "\n",
            "Epoch Number: 265\n",
            "\n",
            "Classification Train Loss: 0.5644680261611938\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.97165984 + 0.08783204 = 1.0594919\n",
            "\n",
            "\n",
            "Epoch Number: 266\n",
            "\n",
            "Classification Train Loss: 0.5647379755973816\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.977509 + 0.087805405 = 1.0653144\n",
            "\n",
            "\n",
            "Epoch Number: 267\n",
            "\n",
            "Classification Train Loss: 0.5629592537879944\n",
            "Training accuracy (Classification): 0.8399999737739563\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9775102 + 0.087742895 = 1.0652531\n",
            "\n",
            "\n",
            "Epoch Number: 268\n",
            "\n",
            "Classification Train Loss: 0.5626814365386963\n",
            "Training accuracy (Classification): 0.8399999737739563\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.97228384 + 0.08764818 = 1.059932\n",
            "\n",
            "\n",
            "Epoch Number: 269\n",
            "\n",
            "Classification Train Loss: 0.5630347728729248\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.972503 + 0.08759145 = 1.0600945\n",
            "\n",
            "\n",
            "Epoch Number: 270\n",
            "\n",
            "Classification Train Loss: 0.5626614689826965\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.97652507 + 0.08756733 = 1.0640924\n",
            "\n",
            "\n",
            "Epoch Number: 271\n",
            "\n",
            "Classification Train Loss: 0.5613865852355957\n",
            "Training accuracy (Classification): 0.8399999737739563\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9793649 + 0.08754347 = 1.0669084\n",
            "\n",
            "\n",
            "Epoch Number: 272\n",
            "\n",
            "Classification Train Loss: 0.5622776746749878\n",
            "Training accuracy (Classification): 0.8399999737739563\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9761654 + 0.08748449 = 1.0636499\n",
            "\n",
            "\n",
            "Epoch Number: 273\n",
            "\n",
            "Classification Train Loss: 0.560806393623352\n",
            "Training accuracy (Classification): 0.8399999737739563\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9743717 + 0.087452985 = 1.0618247\n",
            "\n",
            "\n",
            "Epoch Number: 274\n",
            "\n",
            "Classification Train Loss: 0.5612260103225708\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9766169 + 0.08745306 = 1.06407\n",
            "\n",
            "\n",
            "Epoch Number: 275\n",
            "\n",
            "Classification Train Loss: 0.5603375434875488\n",
            "Training accuracy (Classification): 0.8399999737739563\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9814694 + 0.08748196 = 1.0689514\n",
            "\n",
            "\n",
            "Epoch Number: 276\n",
            "\n",
            "Classification Train Loss: 0.5606717467308044\n",
            "Training accuracy (Classification): 0.8399999737739563\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9800122 + 0.08747074 = 1.067483\n",
            "\n",
            "\n",
            "Epoch Number: 277\n",
            "\n",
            "Classification Train Loss: 0.5594482421875\n",
            "Training accuracy (Classification): 0.8399999737739563\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9773461 + 0.08745841 = 1.0648046\n",
            "\n",
            "\n",
            "Epoch Number: 278\n",
            "\n",
            "Classification Train Loss: 0.5599474310874939\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9788694 + 0.08747727 = 1.0663466\n",
            "\n",
            "\n",
            "Epoch Number: 279\n",
            "\n",
            "Classification Train Loss: 0.5593070983886719\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.98418605 + 0.08752487 = 1.071711\n",
            "\n",
            "\n",
            "Epoch Number: 280\n",
            "\n",
            "Classification Train Loss: 0.5589032173156738\n",
            "Training accuracy (Classification): 0.8399999737739563\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9852397 + 0.087540664 = 1.0727804\n",
            "\n",
            "\n",
            "Epoch Number: 281\n",
            "\n",
            "Classification Train Loss: 0.5585694313049316\n",
            "Training accuracy (Classification): 0.8399999737739563\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.98242384 + 0.08752782 = 1.0699517\n",
            "\n",
            "\n",
            "Epoch Number: 282\n",
            "\n",
            "Classification Train Loss: 0.558207631111145\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.98697776 + 0.08754964 = 1.0745274\n",
            "\n",
            "\n",
            "Epoch Number: 283\n",
            "\n",
            "Classification Train Loss: 0.5578330159187317\n",
            "Training accuracy (Classification): 0.8399999737739563\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.98730284 + 0.08754249 = 1.0748453\n",
            "\n",
            "\n",
            "Epoch Number: 284\n",
            "\n",
            "Classification Train Loss: 0.5572405457496643\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9837905 + 0.087509416 = 1.0712999\n",
            "\n",
            "\n",
            "Epoch Number: 285\n",
            "\n",
            "Classification Train Loss: 0.5588434934616089\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9893322 + 0.087530844 = 1.076863\n",
            "\n",
            "\n",
            "Epoch Number: 286\n",
            "\n",
            "Classification Train Loss: 0.6195331811904907\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 1.0043108 + 0.08770701 = 1.0920179\n",
            "\n",
            "\n",
            "Epoch Number: 287\n",
            "\n",
            "Classification Train Loss: 0.6071768999099731\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.690141\n",
            "MarginLoss + RegLoss: 1.0254737 + 0.08801007 = 1.1134838\n",
            "\n",
            "\n",
            "Epoch Number: 288\n",
            "\n",
            "Classification Train Loss: 0.6008457541465759\n",
            "Training accuracy (Classification): 0.8299999833106995\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.0447439 + 0.08837431 = 1.1331182\n",
            "\n",
            "\n",
            "Epoch Number: 289\n",
            "\n",
            "Classification Train Loss: 0.5996302366256714\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 1.0531093 + 0.088770784 = 1.14188\n",
            "\n",
            "\n",
            "Epoch Number: 290\n",
            "\n",
            "******************** IHT Phase Started ********************\n",
            "\n",
            "\n",
            "Classification Train Loss: 0.5928032994270325\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.8312148 + 0.08534534 = 0.9165601\n",
            "\n",
            "\n",
            "Epoch Number: 291\n",
            "\n",
            "Classification Train Loss: 0.7295868992805481\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.83436656 + 0.08579424 = 0.9201608\n",
            "\n",
            "\n",
            "Epoch Number: 292\n",
            "\n",
            "Classification Train Loss: 0.723574161529541\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.84075564 + 0.08632486 = 0.9270805\n",
            "\n",
            "\n",
            "Epoch Number: 293\n",
            "\n",
            "Classification Train Loss: 0.7127344608306885\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.8510114 + 0.086931586 = 0.937943\n",
            "\n",
            "\n",
            "Epoch Number: 294\n",
            "\n",
            "Classification Train Loss: 0.6979855298995972\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.8655259 + 0.08760297 = 0.9531289\n",
            "\n",
            "\n",
            "Epoch Number: 295\n",
            "\n",
            "Classification Train Loss: 0.6834614872932434\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.88593155 + 0.0883175 = 0.97424906\n",
            "\n",
            "\n",
            "Epoch Number: 296\n",
            "\n",
            "Classification Train Loss: 0.673405110836029\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.90705013 + 0.08904843 = 0.9960986\n",
            "\n",
            "\n",
            "Epoch Number: 297\n",
            "\n",
            "Classification Train Loss: 0.6715633869171143\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.92619985 + 0.08975548 = 1.0159553\n",
            "\n",
            "\n",
            "Epoch Number: 298\n",
            "\n",
            "Classification Train Loss: 0.671962320804596\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9414062 + 0.09043117 = 1.0318373\n",
            "\n",
            "\n",
            "Epoch Number: 299\n",
            "\n",
            "Classification Train Loss: 0.6734805703163147\n",
            "Training accuracy (Classification): 0.7099999785423279\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.9521315 + 0.091055244 = 1.0431868\n",
            "\n",
            "\n",
            "Epoch Number: 300\n",
            "\n",
            "Classification Train Loss: 0.6751677989959717\n",
            "Training accuracy (Classification): 0.7099999785423279\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.9572124 + 0.091597244 = 1.0488096\n",
            "\n",
            "\n",
            "Epoch Number: 301\n",
            "\n",
            "Classification Train Loss: 0.6752428412437439\n",
            "Training accuracy (Classification): 0.7099999785423279\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.95645106 + 0.092051774 = 1.0485028\n",
            "\n",
            "\n",
            "Epoch Number: 302\n",
            "\n",
            "Classification Train Loss: 0.67201828956604\n",
            "Training accuracy (Classification): 0.7099999785423279\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.95028967 + 0.09242708 = 1.0427167\n",
            "\n",
            "\n",
            "Epoch Number: 303\n",
            "\n",
            "Classification Train Loss: 0.6663550138473511\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.9399022 + 0.09272577 = 1.0326279\n",
            "\n",
            "\n",
            "Epoch Number: 304\n",
            "\n",
            "Classification Train Loss: 0.6596516370773315\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9266665 + 0.09298013 = 1.0196466\n",
            "\n",
            "\n",
            "Epoch Number: 305\n",
            "\n",
            "Classification Train Loss: 0.6543720960617065\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.91384804 + 0.09322344 = 1.0070715\n",
            "\n",
            "\n",
            "Epoch Number: 306\n",
            "\n",
            "Classification Train Loss: 0.653673529624939\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.90535724 + 0.093474664 = 0.9988319\n",
            "\n",
            "\n",
            "Epoch Number: 307\n",
            "\n",
            "Classification Train Loss: 0.6545243263244629\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9003653 + 0.09372763 = 0.99409294\n",
            "\n",
            "\n",
            "Epoch Number: 308\n",
            "\n",
            "Classification Train Loss: 0.6550300717353821\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.8979559 + 0.09398164 = 0.9919375\n",
            "\n",
            "\n",
            "Epoch Number: 309\n",
            "\n",
            "Classification Train Loss: 0.6550796031951904\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.8973758 + 0.09423641 = 0.99161226\n",
            "\n",
            "\n",
            "Epoch Number: 310\n",
            "\n",
            "Classification Train Loss: 0.6550423502922058\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.8991779 + 0.09450217 = 0.99368006\n",
            "\n",
            "\n",
            "Epoch Number: 311\n",
            "\n",
            "Classification Train Loss: 0.6541885137557983\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9032336 + 0.09477846 = 0.99801207\n",
            "\n",
            "\n",
            "Epoch Number: 312\n",
            "\n",
            "Classification Train Loss: 0.6521774530410767\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.90939033 + 0.095065735 = 1.004456\n",
            "\n",
            "\n",
            "Epoch Number: 313\n",
            "\n",
            "Classification Train Loss: 0.649659276008606\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9164184 + 0.095354244 = 1.0117726\n",
            "\n",
            "\n",
            "Epoch Number: 314\n",
            "\n",
            "Classification Train Loss: 0.6472330093383789\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.92423797 + 0.095636345 = 1.0198743\n",
            "\n",
            "\n",
            "Epoch Number: 315\n",
            "\n",
            "Classification Train Loss: 0.6449869275093079\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.93320066 + 0.0959036 = 1.0291042\n",
            "\n",
            "\n",
            "Epoch Number: 316\n",
            "\n",
            "Classification Train Loss: 0.6445894837379456\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.94090563 + 0.09612625 = 1.0370319\n",
            "\n",
            "\n",
            "Epoch Number: 317\n",
            "\n",
            "Classification Train Loss: 0.6443079710006714\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.94693726 + 0.09629756 = 1.0432348\n",
            "\n",
            "\n",
            "Epoch Number: 318\n",
            "\n",
            "Classification Train Loss: 0.6442156434059143\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.9508561 + 0.096410125 = 1.0472662\n",
            "\n",
            "\n",
            "Epoch Number: 319\n",
            "\n",
            "Classification Train Loss: 0.6439911127090454\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.95232373 + 0.09645933 = 1.0487831\n",
            "\n",
            "\n",
            "Epoch Number: 320\n",
            "\n",
            "Classification Train Loss: 0.6431000828742981\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.95165175 + 0.09645204 = 1.0481038\n",
            "\n",
            "\n",
            "Epoch Number: 321\n",
            "\n",
            "Classification Train Loss: 0.6415825486183167\n",
            "Training accuracy (Classification): 0.7200000286102295\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9488265 + 0.09639517 = 1.0452217\n",
            "\n",
            "\n",
            "Epoch Number: 322\n",
            "\n",
            "Classification Train Loss: 0.6398172974586487\n",
            "Training accuracy (Classification): 0.7300000190734863\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9460533 + 0.09631733 = 1.0423707\n",
            "\n",
            "\n",
            "Epoch Number: 323\n",
            "\n",
            "Classification Train Loss: 0.6384745836257935\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9432537 + 0.09623222 = 1.0394859\n",
            "\n",
            "\n",
            "Epoch Number: 324\n",
            "\n",
            "Classification Train Loss: 0.6373530030250549\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.94105214 + 0.09615128 = 1.0372034\n",
            "\n",
            "\n",
            "Epoch Number: 325\n",
            "\n",
            "Classification Train Loss: 0.6367836594581604\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9399518 + 0.096086405 = 1.0360382\n",
            "\n",
            "\n",
            "Epoch Number: 326\n",
            "\n",
            "Classification Train Loss: 0.6368763446807861\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9406982 + 0.09604235 = 1.0367405\n",
            "\n",
            "\n",
            "Epoch Number: 327\n",
            "\n",
            "Classification Train Loss: 0.6366164684295654\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9431256 + 0.09601698 = 1.0391426\n",
            "\n",
            "\n",
            "Epoch Number: 328\n",
            "\n",
            "Classification Train Loss: 0.6356935501098633\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.947075 + 0.09600891 = 1.0430839\n",
            "\n",
            "\n",
            "Epoch Number: 329\n",
            "\n",
            "Classification Train Loss: 0.6341699957847595\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.95239484 + 0.09601739 = 1.0484122\n",
            "\n",
            "\n",
            "Epoch Number: 330\n",
            "\n",
            "Classification Train Loss: 0.6326694488525391\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9580903 + 0.09603488 = 1.0541252\n",
            "\n",
            "\n",
            "Epoch Number: 331\n",
            "\n",
            "Classification Train Loss: 0.6316570043563843\n",
            "Training accuracy (Classification): 0.7400000095367432\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.96347183 + 0.096049026 = 1.0595208\n",
            "\n",
            "\n",
            "Epoch Number: 332\n",
            "\n",
            "Classification Train Loss: 0.6310263872146606\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.96784675 + 0.09605 = 1.0638968\n",
            "\n",
            "\n",
            "Epoch Number: 333\n",
            "\n",
            "Classification Train Loss: 0.6309685111045837\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9691861 + 0.096005484 = 1.0651916\n",
            "\n",
            "\n",
            "Epoch Number: 334\n",
            "\n",
            "Classification Train Loss: 0.6304739117622375\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.96777993 + 0.09592041 = 1.0637003\n",
            "\n",
            "\n",
            "Epoch Number: 335\n",
            "\n",
            "Classification Train Loss: 0.629128634929657\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9648866 + 0.09582228 = 1.0607089\n",
            "\n",
            "\n",
            "Epoch Number: 336\n",
            "\n",
            "Classification Train Loss: 0.6278842091560364\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9628904 + 0.09574773 = 1.0586381\n",
            "\n",
            "\n",
            "Epoch Number: 337\n",
            "\n",
            "Classification Train Loss: 0.6278246641159058\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9623575 + 0.095695354 = 1.0580529\n",
            "\n",
            "\n",
            "Epoch Number: 338\n",
            "\n",
            "Classification Train Loss: 0.6276462078094482\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9631601 + 0.09566303 = 1.0588231\n",
            "\n",
            "\n",
            "Epoch Number: 339\n",
            "\n",
            "Classification Train Loss: 0.6271212100982666\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9658646 + 0.095667996 = 1.0615326\n",
            "\n",
            "\n",
            "Epoch Number: 340\n",
            "\n",
            "Classification Train Loss: 0.6261925101280212\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.96908724 + 0.095688604 = 1.0647758\n",
            "\n",
            "\n",
            "Epoch Number: 341\n",
            "\n",
            "Classification Train Loss: 0.6256051659584045\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9721707 + 0.0957116 = 1.0678823\n",
            "\n",
            "\n",
            "Epoch Number: 342\n",
            "\n",
            "Classification Train Loss: 0.625188946723938\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.97415555 + 0.09572467 = 1.0698802\n",
            "\n",
            "\n",
            "Epoch Number: 343\n",
            "\n",
            "Classification Train Loss: 0.6249779462814331\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.97440225 + 0.09571663 = 1.0701189\n",
            "\n",
            "\n",
            "Epoch Number: 344\n",
            "\n",
            "Classification Train Loss: 0.6244165301322937\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.97381866 + 0.09570215 = 1.0695208\n",
            "\n",
            "\n",
            "Epoch Number: 345\n",
            "\n",
            "Classification Train Loss: 0.6239439845085144\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.97301096 + 0.095683895 = 1.0686948\n",
            "\n",
            "\n",
            "Epoch Number: 346\n",
            "\n",
            "Classification Train Loss: 0.6234611868858337\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.97200716 + 0.09566261 = 1.0676697\n",
            "\n",
            "\n",
            "Epoch Number: 347\n",
            "\n",
            "Classification Train Loss: 0.6230291724205017\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.97201085 + 0.09566892 = 1.0676798\n",
            "\n",
            "\n",
            "Epoch Number: 348\n",
            "\n",
            "Classification Train Loss: 0.6226186156272888\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9729319 + 0.09570045 = 1.0686324\n",
            "\n",
            "\n",
            "Epoch Number: 349\n",
            "\n",
            "Classification Train Loss: 0.6220661401748657\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9742065 + 0.095744304 = 1.0699508\n",
            "\n",
            "\n",
            "Epoch Number: 350\n",
            "\n",
            "Classification Train Loss: 0.6215774416923523\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.97507036 + 0.09578025 = 1.0708506\n",
            "\n",
            "\n",
            "Epoch Number: 351\n",
            "\n",
            "Classification Train Loss: 0.6211029887199402\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9755966 + 0.09580938 = 1.071406\n",
            "\n",
            "\n",
            "Epoch Number: 352\n",
            "\n",
            "Classification Train Loss: 0.6206103563308716\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9757878 + 0.09583266 = 1.0716205\n",
            "\n",
            "\n",
            "Epoch Number: 353\n",
            "\n",
            "Classification Train Loss: 0.6201900243759155\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.97488874 + 0.09583826 = 1.070727\n",
            "\n",
            "\n",
            "Epoch Number: 354\n",
            "\n",
            "Classification Train Loss: 0.6195768117904663\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.97300005 + 0.09582827 = 1.0688283\n",
            "\n",
            "\n",
            "Epoch Number: 355\n",
            "\n",
            "Classification Train Loss: 0.6189691424369812\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9716173 + 0.09582385 = 1.0674411\n",
            "\n",
            "\n",
            "Epoch Number: 356\n",
            "\n",
            "Classification Train Loss: 0.6186314225196838\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.97119266 + 0.09583539 = 1.067028\n",
            "\n",
            "\n",
            "Epoch Number: 357\n",
            "\n",
            "Classification Train Loss: 0.618122935295105\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9716396 + 0.09586175 = 1.0675013\n",
            "\n",
            "\n",
            "Epoch Number: 358\n",
            "\n",
            "Classification Train Loss: 0.6174584627151489\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9723767 + 0.09589127 = 1.068268\n",
            "\n",
            "\n",
            "Epoch Number: 359\n",
            "\n",
            "Classification Train Loss: 0.6171615123748779\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.97173584 + 0.09589923 = 1.067635\n",
            "\n",
            "\n",
            "Epoch Number: 360\n",
            "\n",
            "Classification Train Loss: 0.6166789531707764\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9697959 + 0.095887974 = 1.0656838\n",
            "\n",
            "\n",
            "Epoch Number: 361\n",
            "\n",
            "Classification Train Loss: 0.6161026358604431\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9696067 + 0.09590788 = 1.0655146\n",
            "\n",
            "\n",
            "Epoch Number: 362\n",
            "\n",
            "Classification Train Loss: 0.6156675219535828\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.970388 + 0.09595364 = 1.0663416\n",
            "\n",
            "\n",
            "Epoch Number: 363\n",
            "\n",
            "Classification Train Loss: 0.6153401732444763\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.97071505 + 0.095998734 = 1.0667138\n",
            "\n",
            "\n",
            "Epoch Number: 364\n",
            "\n",
            "Classification Train Loss: 0.6149187088012695\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.97062796 + 0.0960434 = 1.0666714\n",
            "\n",
            "\n",
            "Epoch Number: 365\n",
            "\n",
            "Classification Train Loss: 0.6143825054168701\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9701633 + 0.09608797 = 1.0662513\n",
            "\n",
            "\n",
            "Epoch Number: 366\n",
            "\n",
            "Classification Train Loss: 0.6141899824142456\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9716275 + 0.096157566 = 1.067785\n",
            "\n",
            "\n",
            "Epoch Number: 367\n",
            "\n",
            "Classification Train Loss: 0.613518476486206\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.97484833 + 0.09625024 = 1.0710986\n",
            "\n",
            "\n",
            "Epoch Number: 368\n",
            "\n",
            "Classification Train Loss: 0.6133524179458618\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.9770972 + 0.09632941 = 1.0734266\n",
            "\n",
            "\n",
            "Epoch Number: 369\n",
            "\n",
            "Classification Train Loss: 0.6132830381393433\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.9777529 + 0.09638356 = 1.0741365\n",
            "\n",
            "\n",
            "Epoch Number: 370\n",
            "\n",
            "Classification Train Loss: 0.6127877235412598\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.676056\n",
            "MarginLoss + RegLoss: 0.9769641 + 0.09641542 = 1.0733795\n",
            "\n",
            "\n",
            "Epoch Number: 371\n",
            "\n",
            "Classification Train Loss: 0.6119930148124695\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9751714 + 0.09642571 = 1.0715971\n",
            "\n",
            "\n",
            "Epoch Number: 372\n",
            "\n",
            "Classification Train Loss: 0.6116272211074829\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.97523683 + 0.09645732 = 1.0716941\n",
            "\n",
            "\n",
            "Epoch Number: 373\n",
            "\n",
            "Classification Train Loss: 0.6113907098770142\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.976999 + 0.09650834 = 1.0735073\n",
            "\n",
            "\n",
            "Epoch Number: 374\n",
            "\n",
            "Classification Train Loss: 0.6106940507888794\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9788685 + 0.09655249 = 1.075421\n",
            "\n",
            "\n",
            "Epoch Number: 375\n",
            "\n",
            "Classification Train Loss: 0.6102617383003235\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9794675 + 0.09657479 = 1.0760423\n",
            "\n",
            "\n",
            "Epoch Number: 376\n",
            "\n",
            "Classification Train Loss: 0.6098731756210327\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.97890526 + 0.0965776 = 1.0754828\n",
            "\n",
            "\n",
            "Epoch Number: 377\n",
            "\n",
            "Classification Train Loss: 0.6093719005584717\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9786809 + 0.096579246 = 1.0752602\n",
            "\n",
            "\n",
            "Epoch Number: 378\n",
            "\n",
            "Classification Train Loss: 0.6089529395103455\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9787662 + 0.09658017 = 1.0753464\n",
            "\n",
            "\n",
            "Epoch Number: 379\n",
            "\n",
            "Classification Train Loss: 0.6085264682769775\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9800468 + 0.09659461 = 1.0766414\n",
            "\n",
            "\n",
            "Epoch Number: 380\n",
            "\n",
            "Classification Train Loss: 0.6080590486526489\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9807968 + 0.09660448 = 1.0774013\n",
            "\n",
            "\n",
            "Epoch Number: 381\n",
            "\n",
            "Classification Train Loss: 0.6076417565345764\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9811592 + 0.096610546 = 1.0777698\n",
            "\n",
            "\n",
            "Epoch Number: 382\n",
            "\n",
            "Classification Train Loss: 0.6071688532829285\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.98073167 + 0.09661528 = 1.0773469\n",
            "\n",
            "\n",
            "Epoch Number: 383\n",
            "\n",
            "Classification Train Loss: 0.6068218350410461\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9824492 + 0.096655615 = 1.0791048\n",
            "\n",
            "\n",
            "Epoch Number: 384\n",
            "\n",
            "Classification Train Loss: 0.6063381433486938\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.98277307 + 0.096688166 = 1.0794612\n",
            "\n",
            "\n",
            "Epoch Number: 385\n",
            "\n",
            "Classification Train Loss: 0.6058728694915771\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.98335147 + 0.09673954 = 1.080091\n",
            "\n",
            "\n",
            "Epoch Number: 386\n",
            "\n",
            "Classification Train Loss: 0.613873302936554\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9781934 + 0.096706845 = 1.0749003\n",
            "\n",
            "\n",
            "Epoch Number: 387\n",
            "\n",
            "Classification Train Loss: 0.6096028089523315\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.96923625 + 0.09661128 = 1.0658475\n",
            "\n",
            "\n",
            "Epoch Number: 388\n",
            "\n",
            "Classification Train Loss: 0.6077433228492737\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.9611889 + 0.096494295 = 1.0576832\n",
            "\n",
            "\n",
            "Epoch Number: 389\n",
            "\n",
            "Classification Train Loss: 0.6106486320495605\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.9570155 + 0.096399285 = 1.0534148\n",
            "\n",
            "\n",
            "Epoch Number: 390\n",
            "\n",
            "Classification Train Loss: 0.6119773387908936\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.95716166 + 0.09633556 = 1.0534972\n",
            "\n",
            "\n",
            "Epoch Number: 391\n",
            "\n",
            "Classification Train Loss: 0.6100003719329834\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.9611891 + 0.09630137 = 1.0574905\n",
            "\n",
            "\n",
            "Epoch Number: 392\n",
            "\n",
            "Classification Train Loss: 0.6055842638015747\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9671791 + 0.0962736 = 1.0634527\n",
            "\n",
            "\n",
            "Epoch Number: 393\n",
            "\n",
            "Classification Train Loss: 0.6048876643180847\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.97009563 + 0.096204765 = 1.0663004\n",
            "\n",
            "\n",
            "Epoch Number: 394\n",
            "\n",
            "Classification Train Loss: 0.606993556022644\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.96852374 + 0.096088886 = 1.0646126\n",
            "\n",
            "\n",
            "Epoch Number: 395\n",
            "\n",
            "Classification Train Loss: 0.6070659160614014\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.96250236 + 0.095931165 = 1.0584335\n",
            "\n",
            "\n",
            "Epoch Number: 396\n",
            "\n",
            "Classification Train Loss: 0.6042562127113342\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9536468 + 0.09573271 = 1.0493795\n",
            "\n",
            "\n",
            "Epoch Number: 397\n",
            "\n",
            "Classification Train Loss: 0.6014026403427124\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.9449668 + 0.09553923 = 1.040506\n",
            "\n",
            "\n",
            "Epoch Number: 398\n",
            "\n",
            "Classification Train Loss: 0.602189302444458\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.941133 + 0.095403194 = 1.0365362\n",
            "\n",
            "\n",
            "Epoch Number: 399\n",
            "\n",
            "Classification Train Loss: 0.6027010679244995\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9416522 + 0.09531821 = 1.0369704\n",
            "\n",
            "\n",
            "Epoch Number: 400\n",
            "\n",
            "Classification Train Loss: 0.6007732152938843\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9438609 + 0.09525071 = 1.0391116\n",
            "\n",
            "\n",
            "Epoch Number: 401\n",
            "\n",
            "Classification Train Loss: 0.600010335445404\n",
            "Training accuracy (Classification): 0.75\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9464375 + 0.09519586 = 1.0416334\n",
            "\n",
            "\n",
            "Epoch Number: 402\n",
            "\n",
            "Classification Train Loss: 0.6000368595123291\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.947136 + 0.09512681 = 1.0422628\n",
            "\n",
            "\n",
            "Epoch Number: 403\n",
            "\n",
            "Classification Train Loss: 0.6002640128135681\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9461511 + 0.09504455 = 1.0411956\n",
            "\n",
            "\n",
            "Epoch Number: 404\n",
            "\n",
            "Classification Train Loss: 0.5999149084091187\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.94364977 + 0.09495055 = 1.0386003\n",
            "\n",
            "\n",
            "Epoch Number: 405\n",
            "\n",
            "Classification Train Loss: 0.5990628600120544\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.94061005 + 0.09485886 = 1.0354689\n",
            "\n",
            "\n",
            "Epoch Number: 406\n",
            "\n",
            "Classification Train Loss: 0.5981785655021667\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9370867 + 0.094769925 = 1.0318567\n",
            "\n",
            "\n",
            "Epoch Number: 407\n",
            "\n",
            "Classification Train Loss: 0.5979665517807007\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9345507 + 0.0946968 = 1.0292475\n",
            "\n",
            "\n",
            "Epoch Number: 408\n",
            "\n",
            "Classification Train Loss: 0.5980860590934753\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9342044 + 0.094659984 = 1.0288644\n",
            "\n",
            "\n",
            "Epoch Number: 409\n",
            "\n",
            "Classification Train Loss: 0.5979607701301575\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.93635523 + 0.0946603 = 1.0310155\n",
            "\n",
            "\n",
            "Epoch Number: 410\n",
            "\n",
            "Classification Train Loss: 0.597087562084198\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9403237 + 0.09469029 = 1.035014\n",
            "\n",
            "\n",
            "Epoch Number: 411\n",
            "\n",
            "Classification Train Loss: 0.5961003303527832\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9445408 + 0.09472555 = 1.0392663\n",
            "\n",
            "\n",
            "Epoch Number: 412\n",
            "\n",
            "Classification Train Loss: 0.5957518219947815\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9471209 + 0.09473942 = 1.0418603\n",
            "\n",
            "\n",
            "Epoch Number: 413\n",
            "\n",
            "Classification Train Loss: 0.5957582592964172\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.94780743 + 0.094734214 = 1.0425416\n",
            "\n",
            "\n",
            "Epoch Number: 414\n",
            "\n",
            "Classification Train Loss: 0.5952523350715637\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9471885 + 0.09471181 = 1.0419003\n",
            "\n",
            "\n",
            "Epoch Number: 415\n",
            "\n",
            "Classification Train Loss: 0.5945348739624023\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9453841 + 0.0946744 = 1.0400585\n",
            "\n",
            "\n",
            "Epoch Number: 416\n",
            "\n",
            "Classification Train Loss: 0.5939478278160095\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9442044 + 0.094648905 = 1.0388533\n",
            "\n",
            "\n",
            "Epoch Number: 417\n",
            "\n",
            "Classification Train Loss: 0.593672513961792\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.94366395 + 0.09463441 = 1.0382984\n",
            "\n",
            "\n",
            "Epoch Number: 418\n",
            "\n",
            "Classification Train Loss: 0.5940158367156982\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9474815 + 0.09467676 = 1.0421582\n",
            "\n",
            "\n",
            "Epoch Number: 419\n",
            "\n",
            "Classification Train Loss: 0.5928438305854797\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.95146036 + 0.09472407 = 1.0461844\n",
            "\n",
            "\n",
            "Epoch Number: 420\n",
            "\n",
            "Classification Train Loss: 0.5923851132392883\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9538011 + 0.094750814 = 1.0485519\n",
            "\n",
            "\n",
            "Epoch Number: 421\n",
            "\n",
            "Classification Train Loss: 0.5922412872314453\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9546568 + 0.09475904 = 1.0494158\n",
            "\n",
            "\n",
            "Epoch Number: 422\n",
            "\n",
            "Classification Train Loss: 0.5917955040931702\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.95416504 + 0.09475083 = 1.0489159\n",
            "\n",
            "\n",
            "Epoch Number: 423\n",
            "\n",
            "Classification Train Loss: 0.5911782383918762\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9542018 + 0.09475365 = 1.0489554\n",
            "\n",
            "\n",
            "Epoch Number: 424\n",
            "\n",
            "Classification Train Loss: 0.5908342003822327\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9547241 + 0.094766706 = 1.0494908\n",
            "\n",
            "\n",
            "Epoch Number: 425\n",
            "\n",
            "Classification Train Loss: 0.5905119180679321\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9565091 + 0.094793946 = 1.051303\n",
            "\n",
            "\n",
            "Epoch Number: 426\n",
            "\n",
            "Classification Train Loss: 0.5900031924247742\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.95862997 + 0.094829686 = 1.0534596\n",
            "\n",
            "\n",
            "Epoch Number: 427\n",
            "\n",
            "Classification Train Loss: 0.5896399021148682\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.95996284 + 0.09485924 = 1.0548221\n",
            "\n",
            "\n",
            "Epoch Number: 428\n",
            "\n",
            "Classification Train Loss: 0.5892647504806519\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.96058095 + 0.09488344 = 1.0554644\n",
            "\n",
            "\n",
            "Epoch Number: 429\n",
            "\n",
            "Classification Train Loss: 0.5888476371765137\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9631291 + 0.0949268 = 1.0580559\n",
            "\n",
            "\n",
            "Epoch Number: 430\n",
            "\n",
            "Classification Train Loss: 0.5885489583015442\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9648467 + 0.094963945 = 1.0598106\n",
            "\n",
            "\n",
            "Epoch Number: 431\n",
            "\n",
            "Classification Train Loss: 0.5881946086883545\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9658017 + 0.09499575 = 1.0607975\n",
            "\n",
            "\n",
            "Epoch Number: 432\n",
            "\n",
            "Classification Train Loss: 0.5877373218536377\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9661402 + 0.09502308 = 1.0611633\n",
            "\n",
            "\n",
            "Epoch Number: 433\n",
            "\n",
            "Classification Train Loss: 0.5875539183616638\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.96836245 + 0.09507047 = 1.0634329\n",
            "\n",
            "\n",
            "Epoch Number: 434\n",
            "\n",
            "Classification Train Loss: 0.5869529247283936\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.97144294 + 0.09511781 = 1.0665607\n",
            "\n",
            "\n",
            "Epoch Number: 435\n",
            "\n",
            "Classification Train Loss: 0.5868543982505798\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9710117 + 0.09514157 = 1.0661533\n",
            "\n",
            "\n",
            "Epoch Number: 436\n",
            "\n",
            "Classification Train Loss: 0.5862182974815369\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.97262704 + 0.09518683 = 1.0678139\n",
            "\n",
            "\n",
            "Epoch Number: 437\n",
            "\n",
            "Classification Train Loss: 0.5857709646224976\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9751135 + 0.09523322 = 1.0703467\n",
            "\n",
            "\n",
            "Epoch Number: 438\n",
            "\n",
            "Classification Train Loss: 0.5858082175254822\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9739325 + 0.09525774 = 1.0691903\n",
            "\n",
            "\n",
            "Epoch Number: 439\n",
            "\n",
            "Classification Train Loss: 0.586114764213562\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.97754073 + 0.095329314 = 1.07287\n",
            "\n",
            "\n",
            "Epoch Number: 440\n",
            "\n",
            "Classification Train Loss: 0.5853623747825623\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9782324 + 0.09538912 = 1.0736215\n",
            "\n",
            "\n",
            "Epoch Number: 441\n",
            "\n",
            "Classification Train Loss: 0.5849952697753906\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9769689 + 0.09545055 = 1.0724194\n",
            "\n",
            "\n",
            "Epoch Number: 442\n",
            "\n",
            "Classification Train Loss: 0.5851309299468994\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9795781 + 0.09553783 = 1.0751159\n",
            "\n",
            "\n",
            "Epoch Number: 443\n",
            "\n",
            "Classification Train Loss: 0.5842365026473999\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.98118186 + 0.095624894 = 1.0768068\n",
            "\n",
            "\n",
            "Epoch Number: 444\n",
            "\n",
            "Classification Train Loss: 0.5841134786605835\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 0.97919065 + 0.095672525 = 1.0748632\n",
            "\n",
            "\n",
            "Epoch Number: 445\n",
            "\n",
            "Classification Train Loss: 0.5843743681907654\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.98121357 + 0.095748425 = 1.076962\n",
            "\n",
            "\n",
            "Epoch Number: 446\n",
            "\n",
            "Classification Train Loss: 0.5834554433822632\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.98502064 + 0.09584414 = 1.0808648\n",
            "\n",
            "\n",
            "Epoch Number: 447\n",
            "\n",
            "Classification Train Loss: 0.5842190980911255\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.98498243 + 0.09589953 = 1.080882\n",
            "\n",
            "\n",
            "Epoch Number: 448\n",
            "\n",
            "Classification Train Loss: 0.5835731029510498\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9817613 + 0.09591777 = 1.077679\n",
            "\n",
            "\n",
            "Epoch Number: 449\n",
            "\n",
            "Classification Train Loss: 0.5830020308494568\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.98225325 + 0.09596939 = 1.0782226\n",
            "\n",
            "\n",
            "Epoch Number: 450\n",
            "\n",
            "Classification Train Loss: 0.5827469825744629\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.98692 + 0.09605351 = 1.0829735\n",
            "\n",
            "\n",
            "Epoch Number: 451\n",
            "\n",
            "Classification Train Loss: 0.5827701091766357\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9886445 + 0.09611061 = 1.0847551\n",
            "\n",
            "\n",
            "Epoch Number: 452\n",
            "\n",
            "Classification Train Loss: 0.5829620361328125\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9869755 + 0.096130535 = 1.083106\n",
            "\n",
            "\n",
            "Epoch Number: 453\n",
            "\n",
            "Classification Train Loss: 0.5817035436630249\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9843029 + 0.09614494 = 1.0804478\n",
            "\n",
            "\n",
            "Epoch Number: 454\n",
            "\n",
            "Classification Train Loss: 0.5823229551315308\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9853296 + 0.09618356 = 1.0815132\n",
            "\n",
            "\n",
            "Epoch Number: 455\n",
            "\n",
            "Classification Train Loss: 0.5820414423942566\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.98971486 + 0.096244335 = 1.0859592\n",
            "\n",
            "\n",
            "Epoch Number: 456\n",
            "\n",
            "Classification Train Loss: 0.5807647705078125\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9929096 + 0.096296236 = 1.0892059\n",
            "\n",
            "\n",
            "Epoch Number: 457\n",
            "\n",
            "Classification Train Loss: 0.5810832381248474\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9932579 + 0.096325025 = 1.0895829\n",
            "\n",
            "\n",
            "Epoch Number: 458\n",
            "\n",
            "Classification Train Loss: 0.580439567565918\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9918518 + 0.09634865 = 1.0882004\n",
            "\n",
            "\n",
            "Epoch Number: 459\n",
            "\n",
            "Classification Train Loss: 0.5802016258239746\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9932955 + 0.09639556 = 1.089691\n",
            "\n",
            "\n",
            "Epoch Number: 460\n",
            "\n",
            "Classification Train Loss: 0.579933226108551\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99733156 + 0.09646374 = 1.0937953\n",
            "\n",
            "\n",
            "Epoch Number: 461\n",
            "\n",
            "Classification Train Loss: 0.5793986320495605\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.99964833 + 0.096523665 = 1.096172\n",
            "\n",
            "\n",
            "Epoch Number: 462\n",
            "\n",
            "Classification Train Loss: 0.579353392124176\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9979318 + 0.09654587 = 1.0944777\n",
            "\n",
            "\n",
            "Epoch Number: 463\n",
            "\n",
            "Classification Train Loss: 0.5789766907691956\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9991484 + 0.09659283 = 1.0957413\n",
            "\n",
            "\n",
            "Epoch Number: 464\n",
            "\n",
            "Classification Train Loss: 0.5787621736526489\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0030336 + 0.09666241 = 1.099696\n",
            "\n",
            "\n",
            "Epoch Number: 465\n",
            "\n",
            "Classification Train Loss: 0.5781964063644409\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0048724 + 0.09672566 = 1.1015981\n",
            "\n",
            "\n",
            "Epoch Number: 466\n",
            "\n",
            "Classification Train Loss: 0.5781370401382446\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0019033 + 0.09675187 = 1.0986552\n",
            "\n",
            "\n",
            "Epoch Number: 467\n",
            "\n",
            "Classification Train Loss: 0.5784831047058105\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0029416 + 0.09681687 = 1.0997585\n",
            "\n",
            "\n",
            "Epoch Number: 468\n",
            "\n",
            "Classification Train Loss: 0.5781769752502441\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0076196 + 0.09691733 = 1.104537\n",
            "\n",
            "\n",
            "Epoch Number: 469\n",
            "\n",
            "Classification Train Loss: 0.5771081447601318\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.008904 + 0.09699433 = 1.1058983\n",
            "\n",
            "\n",
            "Epoch Number: 470\n",
            "\n",
            "Classification Train Loss: 0.5769694447517395\n",
            "Training accuracy (Classification): 0.7599999904632568\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0056573 + 0.09703472 = 1.102692\n",
            "\n",
            "\n",
            "Epoch Number: 471\n",
            "\n",
            "Classification Train Loss: 0.5773259401321411\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0066323 + 0.097114235 = 1.1037465\n",
            "\n",
            "\n",
            "Epoch Number: 472\n",
            "\n",
            "Classification Train Loss: 0.5769636631011963\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0114423 + 0.09722961 = 1.1086719\n",
            "\n",
            "\n",
            "Epoch Number: 473\n",
            "\n",
            "Classification Train Loss: 0.5760827660560608\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0139241 + 0.09733528 = 1.1112595\n",
            "\n",
            "\n",
            "Epoch Number: 474\n",
            "\n",
            "Classification Train Loss: 0.5764816999435425\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0120785 + 0.097400814 = 1.1094793\n",
            "\n",
            "\n",
            "Epoch Number: 475\n",
            "\n",
            "Classification Train Loss: 0.5754199624061584\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0104524 + 0.09746739 = 1.1079198\n",
            "\n",
            "\n",
            "Epoch Number: 476\n",
            "\n",
            "Classification Train Loss: 0.576148271560669\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0129501 + 0.09756075 = 1.1105108\n",
            "\n",
            "\n",
            "Epoch Number: 477\n",
            "\n",
            "Classification Train Loss: 0.5752200484275818\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0182774 + 0.097676925 = 1.1159543\n",
            "\n",
            "\n",
            "Epoch Number: 478\n",
            "\n",
            "Classification Train Loss: 0.5751513838768005\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0189242 + 0.097752996 = 1.1166773\n",
            "\n",
            "\n",
            "Epoch Number: 479\n",
            "\n",
            "Classification Train Loss: 0.5745906829833984\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0166692 + 0.09780875 = 1.1144779\n",
            "\n",
            "\n",
            "Epoch Number: 480\n",
            "\n",
            "Classification Train Loss: 0.5743581652641296\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0177449 + 0.0978921 = 1.115637\n",
            "\n",
            "\n",
            "Epoch Number: 481\n",
            "\n",
            "Classification Train Loss: 0.5741824507713318\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 1.0227653 + 0.098002866 = 1.1207682\n",
            "\n",
            "\n",
            "Epoch Number: 482\n",
            "\n",
            "Classification Train Loss: 0.5736149549484253\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.619718\n",
            "MarginLoss + RegLoss: 1.0253748 + 0.09810648 = 1.1234813\n",
            "\n",
            "\n",
            "Epoch Number: 483\n",
            "\n",
            "Classification Train Loss: 0.5737508535385132\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0235002 + 0.09817231 = 1.1216725\n",
            "\n",
            "\n",
            "Epoch Number: 484\n",
            "\n",
            "Classification Train Loss: 0.5729321837425232\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.021911 + 0.09824186 = 1.1201528\n",
            "\n",
            "\n",
            "Epoch Number: 485\n",
            "\n",
            "Classification Train Loss: 0.5743628144264221\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0260493 + 0.09836535 = 1.1244146\n",
            "\n",
            "\n",
            "Epoch Number: 486\n",
            "\n",
            "Classification Train Loss: 0.5886971354484558\n",
            "Training accuracy (Classification): 0.7699999809265137\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0190579 + 0.098374866 = 1.1174327\n",
            "\n",
            "\n",
            "Epoch Number: 487\n",
            "\n",
            "Classification Train Loss: 0.5829398036003113\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0137612 + 0.09835275 = 1.112114\n",
            "\n",
            "\n",
            "Epoch Number: 488\n",
            "\n",
            "Classification Train Loss: 0.5845257043838501\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0116104 + 0.09834059 = 1.109951\n",
            "\n",
            "\n",
            "Epoch Number: 489\n",
            "\n",
            "Classification Train Loss: 0.5851529836654663\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0141333 + 0.09836786 = 1.1125011\n",
            "\n",
            "\n",
            "Epoch Number: 490\n",
            "\n",
            "Classification Train Loss: 0.5829263925552368\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0183908 + 0.09838641 = 1.1167772\n",
            "\n",
            "\n",
            "Epoch Number: 491\n",
            "\n",
            "Classification Train Loss: 0.5819925665855408\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.017407 + 0.098329745 = 1.1157367\n",
            "\n",
            "\n",
            "Epoch Number: 492\n",
            "\n",
            "Classification Train Loss: 0.582159698009491\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0105991 + 0.09820564 = 1.1088048\n",
            "\n",
            "\n",
            "Epoch Number: 493\n",
            "\n",
            "Classification Train Loss: 0.5803588628768921\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0054762 + 0.098088354 = 1.1035646\n",
            "\n",
            "\n",
            "Epoch Number: 494\n",
            "\n",
            "Classification Train Loss: 0.5809152722358704\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0044072 + 0.09800567 = 1.1024128\n",
            "\n",
            "\n",
            "Epoch Number: 495\n",
            "\n",
            "Classification Train Loss: 0.5793750286102295\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0061212 + 0.097953305 = 1.1040745\n",
            "\n",
            "\n",
            "Epoch Number: 496\n",
            "\n",
            "Classification Train Loss: 0.5794494152069092\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.002794 + 0.09785504 = 1.1006491\n",
            "\n",
            "\n",
            "Epoch Number: 497\n",
            "\n",
            "Classification Train Loss: 0.5785309672355652\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9961829 + 0.09773137 = 1.0939143\n",
            "\n",
            "\n",
            "Epoch Number: 498\n",
            "\n",
            "Classification Train Loss: 0.5784693956375122\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9933351 + 0.09764479 = 1.0909799\n",
            "\n",
            "\n",
            "Epoch Number: 499\n",
            "\n",
            "Classification Train Loss: 0.5784276723861694\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9933665 + 0.097591065 = 1.0909575\n",
            "\n",
            "\n",
            "Epoch Number: 500\n",
            "\n",
            "Classification Train Loss: 0.5776476263999939\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.9942743 + 0.0975601 = 1.0918344\n",
            "\n",
            "\n",
            "Epoch Number: 501\n",
            "\n",
            "Classification Train Loss: 0.5774803161621094\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.661972\n",
            "MarginLoss + RegLoss: 0.992813 + 0.097528 = 1.090341\n",
            "\n",
            "\n",
            "Epoch Number: 502\n",
            "\n",
            "Classification Train Loss: 0.5772273540496826\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.990006 + 0.09749584 = 1.0875019\n",
            "\n",
            "\n",
            "Epoch Number: 503\n",
            "\n",
            "Classification Train Loss: 0.5768953561782837\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9883752 + 0.09748486 = 1.08586\n",
            "\n",
            "\n",
            "Epoch Number: 504\n",
            "\n",
            "Classification Train Loss: 0.576736330986023\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9878119 + 0.09749314 = 1.0853051\n",
            "\n",
            "\n",
            "Epoch Number: 505\n",
            "\n",
            "Classification Train Loss: 0.5764552354812622\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9881694 + 0.09751899 = 1.0856884\n",
            "\n",
            "\n",
            "Epoch Number: 506\n",
            "\n",
            "Classification Train Loss: 0.5760641694068909\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9893413 + 0.09756105 = 1.0869024\n",
            "\n",
            "\n",
            "Epoch Number: 507\n",
            "\n",
            "Classification Train Loss: 0.5756863951683044\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9898065 + 0.09761017 = 1.0874166\n",
            "\n",
            "\n",
            "Epoch Number: 508\n",
            "\n",
            "Classification Train Loss: 0.5753772854804993\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.98963195 + 0.09766597 = 1.0872979\n",
            "\n",
            "\n",
            "Epoch Number: 509\n",
            "\n",
            "Classification Train Loss: 0.5749304294586182\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.98887724 + 0.09772818 = 1.0866054\n",
            "\n",
            "\n",
            "Epoch Number: 510\n",
            "\n",
            "Classification Train Loss: 0.5746315717697144\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.98908794 + 0.09780446 = 1.0868924\n",
            "\n",
            "\n",
            "Epoch Number: 511\n",
            "\n",
            "Classification Train Loss: 0.5742737054824829\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99020284 + 0.09789377 = 1.0880966\n",
            "\n",
            "\n",
            "Epoch Number: 512\n",
            "\n",
            "Classification Train Loss: 0.5738341808319092\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9926548 + 0.09799603 = 1.0906508\n",
            "\n",
            "\n",
            "Epoch Number: 513\n",
            "\n",
            "Classification Train Loss: 0.5733966827392578\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99244666 + 0.09807217 = 1.0905188\n",
            "\n",
            "\n",
            "Epoch Number: 514\n",
            "\n",
            "Classification Train Loss: 0.5730214715003967\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9945728 + 0.09816534 = 1.0927382\n",
            "\n",
            "\n",
            "Epoch Number: 515\n",
            "\n",
            "Classification Train Loss: 0.5728546977043152\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9945151 + 0.09823435 = 1.0927495\n",
            "\n",
            "\n",
            "Epoch Number: 516\n",
            "\n",
            "Classification Train Loss: 0.5724892020225525\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9949928 + 0.098296106 = 1.0932889\n",
            "\n",
            "\n",
            "Epoch Number: 517\n",
            "\n",
            "Classification Train Loss: 0.572290301322937\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99683106 + 0.098353654 = 1.0951847\n",
            "\n",
            "\n",
            "Epoch Number: 518\n",
            "\n",
            "Classification Train Loss: 0.5724157094955444\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9948862 + 0.09836132 = 1.0932475\n",
            "\n",
            "\n",
            "Epoch Number: 519\n",
            "\n",
            "Classification Train Loss: 0.5723512768745422\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9975779 + 0.09839788 = 1.0959758\n",
            "\n",
            "\n",
            "Epoch Number: 520\n",
            "\n",
            "Classification Train Loss: 0.5721423029899597\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9963972 + 0.09838668 = 1.0947839\n",
            "\n",
            "\n",
            "Epoch Number: 521\n",
            "\n",
            "Classification Train Loss: 0.5716491341590881\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99555385 + 0.09836754 = 1.0939214\n",
            "\n",
            "\n",
            "Epoch Number: 522\n",
            "\n",
            "Classification Train Loss: 0.5716249942779541\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9968184 + 0.098368995 = 1.0951874\n",
            "\n",
            "\n",
            "Epoch Number: 523\n",
            "\n",
            "Classification Train Loss: 0.5714274644851685\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9959765 + 0.098338194 = 1.0943147\n",
            "\n",
            "\n",
            "Epoch Number: 524\n",
            "\n",
            "Classification Train Loss: 0.5710820555686951\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99490535 + 0.09830794 = 1.0932133\n",
            "\n",
            "\n",
            "Epoch Number: 525\n",
            "\n",
            "Classification Train Loss: 0.5712064504623413\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99697244 + 0.09831551 = 1.0952879\n",
            "\n",
            "\n",
            "Epoch Number: 526\n",
            "\n",
            "Classification Train Loss: 0.5711836218833923\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99484706 + 0.09827256 = 1.0931196\n",
            "\n",
            "\n",
            "Epoch Number: 527\n",
            "\n",
            "Classification Train Loss: 0.5709841251373291\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99692076 + 0.09827133 = 1.0951921\n",
            "\n",
            "\n",
            "Epoch Number: 528\n",
            "\n",
            "Classification Train Loss: 0.5707632899284363\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9965234 + 0.09825002 = 1.0947734\n",
            "\n",
            "\n",
            "Epoch Number: 529\n",
            "\n",
            "Classification Train Loss: 0.570340633392334\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99449235 + 0.09821205 = 1.0927044\n",
            "\n",
            "\n",
            "Epoch Number: 530\n",
            "\n",
            "Classification Train Loss: 0.5716254115104675\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9990088 + 0.098223574 = 1.0972323\n",
            "\n",
            "\n",
            "Epoch Number: 531\n",
            "\n",
            "Classification Train Loss: 0.5704531669616699\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9987035 + 0.098197475 = 1.0969009\n",
            "\n",
            "\n",
            "Epoch Number: 532\n",
            "\n",
            "Classification Train Loss: 0.569854199886322\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9967822 + 0.09815562 = 1.0949378\n",
            "\n",
            "\n",
            "Epoch Number: 533\n",
            "\n",
            "Classification Train Loss: 0.570932149887085\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9997064 + 0.098155625 = 1.097862\n",
            "\n",
            "\n",
            "Epoch Number: 534\n",
            "\n",
            "Classification Train Loss: 0.5695751905441284\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0062605 + 0.09819209 = 1.1044526\n",
            "\n",
            "\n",
            "Epoch Number: 535\n",
            "\n",
            "Classification Train Loss: 0.5737079977989197\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.002813 + 0.098147415 = 1.1009604\n",
            "\n",
            "\n",
            "Epoch Number: 536\n",
            "\n",
            "Classification Train Loss: 0.5699942708015442\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9951213 + 0.09803494 = 1.0931562\n",
            "\n",
            "\n",
            "Epoch Number: 537\n",
            "\n",
            "Classification Train Loss: 0.5749399662017822\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 0.9944531 + 0.097986475 = 1.0924395\n",
            "\n",
            "\n",
            "Epoch Number: 538\n",
            "\n",
            "Classification Train Loss: 0.576299250125885\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9983705 + 0.09799434 = 1.0963649\n",
            "\n",
            "\n",
            "Epoch Number: 539\n",
            "\n",
            "Classification Train Loss: 0.570712149143219\n",
            "Training accuracy (Classification): 0.7799999713897705\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0098593 + 0.09804596 = 1.1079053\n",
            "\n",
            "\n",
            "Epoch Number: 540\n",
            "\n",
            "Classification Train Loss: 0.5754753947257996\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0100764 + 0.09800026 = 1.1080767\n",
            "\n",
            "\n",
            "Epoch Number: 541\n",
            "\n",
            "Classification Train Loss: 0.5756697654724121\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0000328 + 0.09786832 = 1.0979011\n",
            "\n",
            "\n",
            "Epoch Number: 542\n",
            "\n",
            "Classification Train Loss: 0.5694627165794373\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99565804 + 0.09778606 = 1.0934441\n",
            "\n",
            "\n",
            "Epoch Number: 543\n",
            "\n",
            "Classification Train Loss: 0.5726941823959351\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9966463 + 0.0977571 = 1.0944034\n",
            "\n",
            "\n",
            "Epoch Number: 544\n",
            "\n",
            "Classification Train Loss: 0.5706819295883179\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0028272 + 0.09777495 = 1.1006021\n",
            "\n",
            "\n",
            "Epoch Number: 545\n",
            "\n",
            "Classification Train Loss: 0.5690213441848755\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0032798 + 0.097747914 = 1.1010277\n",
            "\n",
            "\n",
            "Epoch Number: 546\n",
            "\n",
            "Classification Train Loss: 0.5694257020950317\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99735796 + 0.09766723 = 1.0950252\n",
            "\n",
            "\n",
            "Epoch Number: 547\n",
            "\n",
            "Classification Train Loss: 0.5694124698638916\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9952368 + 0.09763066 = 1.0928675\n",
            "\n",
            "\n",
            "Epoch Number: 548\n",
            "\n",
            "Classification Train Loss: 0.5703499913215637\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9978924 + 0.09764182 = 1.0955342\n",
            "\n",
            "\n",
            "Epoch Number: 549\n",
            "\n",
            "Classification Train Loss: 0.5685938000679016\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0038534 + 0.09768841 = 1.1015419\n",
            "\n",
            "\n",
            "Epoch Number: 550\n",
            "\n",
            "Classification Train Loss: 0.570441722869873\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0005826 + 0.09765692 = 1.0982395\n",
            "\n",
            "\n",
            "Epoch Number: 551\n",
            "\n",
            "Classification Train Loss: 0.5680722594261169\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99603486 + 0.09762299 = 1.0936579\n",
            "\n",
            "\n",
            "Epoch Number: 552\n",
            "\n",
            "Classification Train Loss: 0.5686219334602356\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99502957 + 0.09762894 = 1.0926585\n",
            "\n",
            "\n",
            "Epoch Number: 553\n",
            "\n",
            "Classification Train Loss: 0.568873405456543\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9986519 + 0.09767945 = 1.0963314\n",
            "\n",
            "\n",
            "Epoch Number: 554\n",
            "\n",
            "Classification Train Loss: 0.5672838687896729\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0015016 + 0.09773448 = 1.099236\n",
            "\n",
            "\n",
            "Epoch Number: 555\n",
            "\n",
            "Classification Train Loss: 0.5681759119033813\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9980625 + 0.09774068 = 1.0958031\n",
            "\n",
            "\n",
            "Epoch Number: 556\n",
            "\n",
            "Classification Train Loss: 0.5670834183692932\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99743485 + 0.097777635 = 1.0952125\n",
            "\n",
            "\n",
            "Epoch Number: 557\n",
            "\n",
            "Classification Train Loss: 0.5671738386154175\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9989583 + 0.09784239 = 1.0968007\n",
            "\n",
            "\n",
            "Epoch Number: 558\n",
            "\n",
            "Classification Train Loss: 0.5666260123252869\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0030435 + 0.09793268 = 1.1009762\n",
            "\n",
            "\n",
            "Epoch Number: 559\n",
            "\n",
            "Classification Train Loss: 0.5676127076148987\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99929607 + 0.09794295 = 1.097239\n",
            "\n",
            "\n",
            "Epoch Number: 560\n",
            "\n",
            "Classification Train Loss: 0.5664926767349243\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99951744 + 0.09798679 = 1.0975043\n",
            "\n",
            "\n",
            "Epoch Number: 561\n",
            "\n",
            "Classification Train Loss: 0.5665637254714966\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0061544 + 0.0980761 = 1.1042305\n",
            "\n",
            "\n",
            "Epoch Number: 562\n",
            "\n",
            "Classification Train Loss: 0.5686064958572388\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0040001 + 0.098084256 = 1.1020843\n",
            "\n",
            "\n",
            "Epoch Number: 563\n",
            "\n",
            "Classification Train Loss: 0.5663804411888123\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.9986692 + 0.098026715 = 1.0966959\n",
            "\n",
            "\n",
            "Epoch Number: 564\n",
            "\n",
            "Classification Train Loss: 0.5693542957305908\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99919754 + 0.09802333 = 1.0972209\n",
            "\n",
            "\n",
            "Epoch Number: 565\n",
            "\n",
            "Classification Train Loss: 0.5687721967697144\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0055615 + 0.098069 = 1.1036304\n",
            "\n",
            "\n",
            "Epoch Number: 566\n",
            "\n",
            "Classification Train Loss: 0.566467821598053\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0054413 + 0.09804021 = 1.1034815\n",
            "\n",
            "\n",
            "Epoch Number: 567\n",
            "\n",
            "Classification Train Loss: 0.5660774111747742\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.000583 + 0.09794999 = 1.098533\n",
            "\n",
            "\n",
            "Epoch Number: 568\n",
            "\n",
            "Classification Train Loss: 0.5667874217033386\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0017054 + 0.0979185 = 1.0996239\n",
            "\n",
            "\n",
            "Epoch Number: 569\n",
            "\n",
            "Classification Train Loss: 0.5654298067092896\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0077535 + 0.097931705 = 1.1056852\n",
            "\n",
            "\n",
            "Epoch Number: 570\n",
            "\n",
            "Classification Train Loss: 0.567812442779541\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0035497 + 0.09785807 = 1.1014078\n",
            "\n",
            "\n",
            "Epoch Number: 571\n",
            "\n",
            "Classification Train Loss: 0.5649666786193848\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 0.99969053 + 0.09778084 = 1.0974714\n",
            "\n",
            "\n",
            "Epoch Number: 572\n",
            "\n",
            "******************** Sparse Retraining Phase Started ********************\n",
            "\n",
            "\n",
            "Classification Train Loss: 0.6308972835540771\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0073141 + 0.097883224 = 1.1051973\n",
            "\n",
            "\n",
            "Epoch Number: 573\n",
            "\n",
            "Classification Train Loss: 0.6175570487976074\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0263516 + 0.09814373 = 1.1244953\n",
            "\n",
            "\n",
            "Epoch Number: 574\n",
            "\n",
            "Classification Train Loss: 0.6023499965667725\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0488856 + 0.09850416 = 1.1473898\n",
            "\n",
            "\n",
            "Epoch Number: 575\n",
            "\n",
            "Classification Train Loss: 0.6019395589828491\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0659454 + 0.098882355 = 1.1648277\n",
            "\n",
            "\n",
            "Epoch Number: 576\n",
            "\n",
            "Classification Train Loss: 0.6060542464256287\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0688351 + 0.09922744 = 1.1680626\n",
            "\n",
            "\n",
            "Epoch Number: 577\n",
            "\n",
            "Classification Train Loss: 0.6032288074493408\n",
            "Training accuracy (Classification): 0.7900000214576721\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.058432 + 0.099522285 = 1.1579542\n",
            "\n",
            "\n",
            "Epoch Number: 578\n",
            "\n",
            "Classification Train Loss: 0.5917232036590576\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0448011 + 0.09982898 = 1.1446301\n",
            "\n",
            "\n",
            "Epoch Number: 579\n",
            "\n",
            "Classification Train Loss: 0.5823673009872437\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0345773 + 0.10018141 = 1.1347587\n",
            "\n",
            "\n",
            "Epoch Number: 580\n",
            "\n",
            "Classification Train Loss: 0.5802674889564514\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0320363 + 0.10060064 = 1.1326369\n",
            "\n",
            "\n",
            "Epoch Number: 581\n",
            "\n",
            "Classification Train Loss: 0.5837989449501038\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0402188 + 0.101112984 = 1.1413318\n",
            "\n",
            "\n",
            "Epoch Number: 582\n",
            "\n",
            "Classification Train Loss: 0.5778531432151794\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0557479 + 0.10166064 = 1.1574085\n",
            "\n",
            "\n",
            "Epoch Number: 583\n",
            "\n",
            "Classification Train Loss: 0.5702210068702698\n",
            "Training accuracy (Classification): 0.8199999928474426\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0707059 + 0.1022097 = 1.1729156\n",
            "\n",
            "\n",
            "Epoch Number: 584\n",
            "\n",
            "Classification Train Loss: 0.5720963478088379\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0781329 + 0.10270643 = 1.1808393\n",
            "\n",
            "\n",
            "Epoch Number: 585\n",
            "\n",
            "Classification Train Loss: 0.5727452635765076\n",
            "Training accuracy (Classification): 0.800000011920929\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0749638 + 0.103109695 = 1.1780735\n",
            "\n",
            "\n",
            "Epoch Number: 586\n",
            "\n",
            "Classification Train Loss: 0.5673891305923462\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0663857 + 0.103456706 = 1.1698425\n",
            "\n",
            "\n",
            "Epoch Number: 587\n",
            "\n",
            "Classification Train Loss: 0.5692707896232605\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0673927 + 0.10384791 = 1.1712406\n",
            "\n",
            "\n",
            "Epoch Number: 588\n",
            "\n",
            "Classification Train Loss: 0.5715020895004272\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0763601 + 0.10427647 = 1.1806365\n",
            "\n",
            "\n",
            "Epoch Number: 589\n",
            "\n",
            "Classification Train Loss: 0.5671710968017578\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0889186 + 0.10469135 = 1.19361\n",
            "\n",
            "\n",
            "Epoch Number: 590\n",
            "\n",
            "Classification Train Loss: 0.5663440227508545\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.0957295 + 0.10499715 = 1.2007266\n",
            "\n",
            "\n",
            "Epoch Number: 591\n",
            "\n",
            "Classification Train Loss: 0.568901777267456\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.091827 + 0.10517521 = 1.1970023\n",
            "\n",
            "\n",
            "Epoch Number: 592\n",
            "\n",
            "Classification Train Loss: 0.5659356117248535\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0868217 + 0.10529128 = 1.1921129\n",
            "\n",
            "\n",
            "Epoch Number: 593\n",
            "\n",
            "Classification Train Loss: 0.5663408041000366\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0852826 + 0.10539625 = 1.1906788\n",
            "\n",
            "\n",
            "Epoch Number: 594\n",
            "\n",
            "Classification Train Loss: 0.5674217939376831\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0897223 + 0.105523616 = 1.1952459\n",
            "\n",
            "\n",
            "Epoch Number: 595\n",
            "\n",
            "Classification Train Loss: 0.5657798051834106\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.096656 + 0.105626374 = 1.2022823\n",
            "\n",
            "\n",
            "Epoch Number: 596\n",
            "\n",
            "Classification Train Loss: 0.5655314326286316\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.647887\n",
            "MarginLoss + RegLoss: 1.1004845 + 0.10566404 = 1.2061485\n",
            "\n",
            "\n",
            "Epoch Number: 597\n",
            "\n",
            "Classification Train Loss: 0.5670004487037659\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0966945 + 0.10561212 = 1.2023066\n",
            "\n",
            "\n",
            "Epoch Number: 598\n",
            "\n",
            "Classification Train Loss: 0.5647528767585754\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0889603 + 0.10550126 = 1.1944616\n",
            "\n",
            "\n",
            "Epoch Number: 599\n",
            "\n",
            "Classification Train Loss: 0.5647345185279846\n",
            "Training accuracy (Classification): 0.8100000023841858\n",
            "Test accuracy 0.633803\n",
            "MarginLoss + RegLoss: 1.0898193 + 0.10545839 = 1.1952777\n",
            "\n",
            "\n",
            "Non-Zero : 583.0 Model Size: 3.7890625 KB hasSparse: True\n",
            "\n",
            "For Classification, Maximum Test accuracy at compressed model size(including early stopping): 0.6760563 at Epoch: 371\n",
            "Final Test Accuracy: 0.63380283\n",
            "The Model Directory: /content\n",
            "\n"
          ]
        }
      ]
    }
  ]
}