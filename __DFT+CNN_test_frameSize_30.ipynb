{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "__DFT+CNN_test.ipynb",
      "provenance": [],
      "mount_file_id": "18r69LbxCgtdv9i1dK5FI_CrmZusiZnJ0",
      "authorship_tag": "ABX9TyNgdKXWS+TQwXHzn3VuoZ5M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakibchowdhury131/railcop/blob/main/__DFT%2BCNN_test_frameSize_30.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS-nyQLcCfhQ",
        "outputId": "f7bae032-4208-4807-c100-54e75c651a7c"
      },
      "source": [
        "!pip install -q tensorflow==2.2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 516.2 MB 4.1 kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 55.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 42.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 454 kB 51.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-4d4ZklblM9",
        "outputId": "57095453-8ad8-4fa1-de63-c734b12285fd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMGFU-7Vg8Y6"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1)\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwBbdKz5hHoU"
      },
      "source": [
        "import os\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK4WfmLUCxO_",
        "outputId": "ad365073-49cf-4f5d-92ee-a48abc598148"
      },
      "source": [
        "label0 = pd.read_csv('/content/drive/MyDrive/RailCop/New Files/Sakib/data/label0/Copy of train_1.csv')\n",
        "label1 = pd.read_csv('/content/drive/MyDrive/RailCop/New Files/Sakib/data/label1/Copy of train_1.csv')\n",
        "print(label1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Sensor1  Sensor2  ...  Sensor2+Sensor4  Sensor1+Sensor2+Sensor3\n",
            "0           2        9  ...               10                       12\n",
            "1           4        9  ...                9                       13\n",
            "2           4        9  ...               11                       15\n",
            "3           4       11  ...               12                       16\n",
            "4           2        9  ...               10                       12\n",
            "...       ...      ...  ...              ...                      ...\n",
            "5384        3        9  ...               10                       13\n",
            "5385        3       10  ...               11                       14\n",
            "5386        4        8  ...                9                       13\n",
            "5387        3        9  ...               10                       13\n",
            "5388        3       10  ...               12                       15\n",
            "\n",
            "[5389 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSHgZYxHEQjv",
        "outputId": "65d96235-95db-4de6-813d-a96f5a39b3b8"
      },
      "source": [
        "__fullVector0 = label0['Sensor1+Sensor2+Sensor3'].to_numpy()\n",
        "__fullVector1 = label1['Sensor1+Sensor2+Sensor3'].to_numpy()\n",
        "\n",
        "\n",
        "print(__fullVector0.shape)\n",
        "print(__fullVector1.shape)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23050,)\n",
            "(5389,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxHOcgAKEzFD"
      },
      "source": [
        "__frameSize = 30\n",
        "\n",
        "## label 0 framing\n",
        "\n",
        "__numFrames0 = int(__fullVector0.shape[0] / __frameSize)\n",
        "__frames0 = np.zeros((__numFrames0,__frameSize))\n",
        "for i in range (0, __numFrames0):\n",
        "  for j in range (0, __frameSize):\n",
        "    __frames0[i][j] = __fullVector0[i*__frameSize+j]"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLdPYaw6InIu"
      },
      "source": [
        "## label 1 framing\n",
        "\n",
        "__numFrames1 = int(__fullVector1.shape[0] / __frameSize)\n",
        "__frames1 = np.zeros((__numFrames1,__frameSize))\n",
        "for i in range (0, __numFrames1):\n",
        "  for j in range (0, __frameSize):\n",
        "    __frames1[i][j] = __fullVector1[i*__frameSize+j]"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaiwVxH2JDM1",
        "outputId": "01262a56-f556-4868-867b-f45b74b2270e"
      },
      "source": [
        "__frames0.shape"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcL-0u7tJIe8",
        "outputId": "8683ce99-51a4-4f46-f45e-8327cf6008ce"
      },
      "source": [
        "__frames1.shape"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(179, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCU13F4tJR58"
      },
      "source": [
        "__maxFrames = __frames1.shape[0]\n",
        "__label0 = __frames0[0:__maxFrames, :]\n",
        "__label1 = __frames1[0:__maxFrames, :]"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HuAiNmf6NnQ",
        "outputId": "b6cacab4-8415-4dac-adda-6f854c2592f7"
      },
      "source": [
        "Y0 = np.zeros(__label0.shape[0])\n",
        "Y1 = np.ones(__label1.shape[0])\n",
        "print(Y0.shape)\n",
        "print(Y1.shape)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(179,)\n",
            "(179,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0fbc4SIPY13"
      },
      "source": [
        "## Applying DFT\n",
        "## finding Fourier Co-efficients Xn\n",
        "\n",
        "def get_xn(samples,n):\n",
        "    L  = len(samples)\n",
        "    ks = np.arange(0,L,1)\n",
        "    xn = np.sum(samples*np.exp((1j*2*np.pi*ks*n)/L))/L\n",
        "    return(xn)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vsN2UOEPzP2"
      },
      "source": [
        "## Compute Fourier coefficients only up to the Nyquest Limit Xn, n=1,...,L/2 and \n",
        "## multiply the absolute value of the Fourier coefficients by 2, to account for \n",
        "## the symetry of the Fourier coefficients above the Nyquest Limit.\n",
        "\n",
        "\n",
        "def get_xns(samples):\n",
        "    mag = []\n",
        "    L = len(samples)\n",
        "    for n in range(int(L/2)): # Nyquest Limit\n",
        "        mag.append(np.abs(get_xn(samples,n))*2)\n",
        "    return(mag)\n",
        "mag = get_xns(__frames0[2])"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "qKa6Pah3QEik",
        "outputId": "06dc1f97-b046-446c-eb16-6cdef9c80125"
      },
      "source": [
        "## Fourier Plot \n",
        "\n",
        "def get_Hz_scale_vec(ks,sample_rate,Npoints):\n",
        "    freq_Hz = ks*sample_rate/Npoints\n",
        "    freq_Hz  = [int(i) for i in freq_Hz ] \n",
        "    return(freq_Hz )\n",
        "Nxlim = 12\n",
        "sample_rate = int(9600/4)\n",
        "ks   = np.linspace(0,len(mag),Nxlim)\n",
        "ksHz = get_Hz_scale_vec(ks,sample_rate,len(__frames1[0]))\n",
        "\n",
        "plt.figure(figsize=(20,3))\n",
        "plt.plot(mag[1:])\n",
        "plt.xticks(ks,ksHz)\n",
        "plt.title(\"Frequency Domain\")\n",
        "plt.xlabel(\"Frequency (Hz)\")\n",
        "plt.ylabel(\"|Fourier Coefficient|\")\n",
        "plt.show()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "0OawIhlaWke4",
        "outputId": "768267ee-8eea-4450-e11b-e6487471a5be"
      },
      "source": [
        "plt.plot (__label1[3])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3765918090>]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJUw7uZnRSqS"
      },
      "source": [
        "## Fourier coefficients of label0 \n",
        "__fourier0 = np.zeros((__maxFrames,len(mag)))\n",
        "for i in range(0, __maxFrames):\n",
        "  __fourier0[i] = np.array(get_xns(__label0[i]))\n",
        "\n",
        "\n",
        "\n",
        "## Fourier coefficients of label1 \n",
        "__fourier1 = np.zeros((__maxFrames,len(mag)))\n",
        "for i in range(0, __maxFrames):\n",
        "  __fourier1[i] = np.array(get_xns(__label1[i]))"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CnpRw747nep",
        "outputId": "8b967231-7bb9-4fe9-e7cd-248c6717e382"
      },
      "source": [
        "X = np.asarray(np.concatenate((__fourier0[:, 1:], __fourier1[:, 1:]), axis = 0), dtype=np.float32)\n",
        "Y = np.asarray(np.concatenate((Y0, Y1), axis = 0), dtype = np.float32)\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(358, 14)\n",
            "(358,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkru_rqG8y_j"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "X, Y = shuffle(X,Y)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlQZ0BlbVWLM",
        "outputId": "d830959c-a6c6-478d-bb7f-1a080b2a1ba9"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(358, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IkBKV3V8SKV",
        "outputId": "d7e3070b-0a75-4a78-ea64-fd07ee598bcb"
      },
      "source": [
        "def network():\n",
        "  __input = keras.Input((X.shape[1], 1))\n",
        "  __conv1 = keras.layers.Conv1D(filters = 4, kernel_size = 3, activation = 'relu')(__input)\n",
        "  __conv2 = keras.layers.Conv1D(filters = 8, kernel_size = 3, activation = 'relu')(__conv1)\n",
        "  __flat4 = keras.layers.Flatten()(__conv2)\n",
        "  __dense3 = keras.layers.Dense(16, activation = 'relu')(__flat4)\n",
        "  __output = keras.layers.Dense(1, activation = 'sigmoid')(__dense3)\n",
        "\n",
        "  model = keras.Model(inputs = __input, outputs = __output)\n",
        "  return model \n",
        "\n",
        "\n",
        "\n",
        "model = network()\n",
        "model.summary()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 14, 1)]           0         \n",
            "                                                                 \n",
            " conv1d_12 (Conv1D)          (None, 12, 4)             16        \n",
            "                                                                 \n",
            " conv1d_13 (Conv1D)          (None, 10, 8)             104       \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 80)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 16)                1296      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,433\n",
            "Trainable params: 1,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjqPOWy4-ihx"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "                      optimizer= 'adam',\n",
        "                      metrics=['accuracy'])"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuiIE4FR-1LG",
        "outputId": "d79badbd-9870-4efb-f6f5-86cc66bb51ce"
      },
      "source": [
        "__modelVersion = '__timeSeriesTest1.0'\n",
        "\n",
        "weight_saver = tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/RailCop/New Files/Sakib/models/'+__modelVersion, monitor='val_accuracy', \n",
        "                                save_best_only=True, save_weights_only=False, mode= 'max')\n",
        "\n",
        "annealer = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
        "                              patience=5, min_lr=0.000001,mode= 'min')\n",
        "\n",
        "\n",
        "hist = model.fit( x = X , \n",
        "                  y = Y, \n",
        "                  batch_size = 4,\n",
        "                  epochs = 600,\n",
        "                  callbacks = [weight_saver , annealer],\n",
        "                  validation_split = 0.2,\n",
        "                  shuffle = True,\n",
        "                  verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.6962 - accuracy: 0.4685INFO:tensorflow:Assets written to: /content/drive/MyDrive/RailCop/New Files/Sakib/models/__timeSeriesTest1.0/assets\n",
            "72/72 [==============================] - 2s 20ms/step - loss: 0.6962 - accuracy: 0.4685 - val_loss: 0.6917 - val_accuracy: 0.5278 - lr: 0.0010\n",
            "Epoch 2/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.4825 - val_loss: 0.6900 - val_accuracy: 0.5139 - lr: 0.0010\n",
            "Epoch 3/600\n",
            "58/72 [=======================>......] - ETA: 0s - loss: 0.6899 - accuracy: 0.5431INFO:tensorflow:Assets written to: /content/drive/MyDrive/RailCop/New Files/Sakib/models/__timeSeriesTest1.0/assets\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.6920 - accuracy: 0.5245 - val_loss: 0.6876 - val_accuracy: 0.5417 - lr: 0.0010\n",
            "Epoch 4/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6891 - accuracy: 0.5490 - val_loss: 0.6867 - val_accuracy: 0.5417 - lr: 0.0010\n",
            "Epoch 5/600\n",
            "63/72 [=========================>....] - ETA: 0s - loss: 0.6859 - accuracy: 0.5635INFO:tensorflow:Assets written to: /content/drive/MyDrive/RailCop/New Files/Sakib/models/__timeSeriesTest1.0/assets\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.6864 - accuracy: 0.5629 - val_loss: 0.6841 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 6/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.5979 - val_loss: 0.6830 - val_accuracy: 0.5417 - lr: 0.0010\n",
            "Epoch 7/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.5874 - val_loss: 0.6793 - val_accuracy: 0.5278 - lr: 0.0010\n",
            "Epoch 8/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.5839 - val_loss: 0.6778 - val_accuracy: 0.5972 - lr: 0.0010\n",
            "Epoch 9/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.6119 - val_loss: 0.6745 - val_accuracy: 0.6111 - lr: 0.0010\n",
            "Epoch 10/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.5944 - val_loss: 0.6719 - val_accuracy: 0.5556 - lr: 0.0010\n",
            "Epoch 11/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.5944 - val_loss: 0.6687 - val_accuracy: 0.6111 - lr: 0.0010\n",
            "Epoch 12/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.6189 - val_loss: 0.6704 - val_accuracy: 0.5417 - lr: 0.0010\n",
            "Epoch 13/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6659 - accuracy: 0.6189 - val_loss: 0.6635 - val_accuracy: 0.5972 - lr: 0.0010\n",
            "Epoch 14/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.6049 - val_loss: 0.6643 - val_accuracy: 0.5278 - lr: 0.0010\n",
            "Epoch 15/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.6189 - val_loss: 0.6593 - val_accuracy: 0.5694 - lr: 0.0010\n",
            "Epoch 16/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.6434 - val_loss: 0.6583 - val_accuracy: 0.5833 - lr: 0.0010\n",
            "Epoch 17/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6364 - val_loss: 0.6578 - val_accuracy: 0.6111 - lr: 0.0010\n",
            "Epoch 18/600\n",
            "49/72 [===================>..........] - ETA: 0s - loss: 0.6548 - accuracy: 0.5969INFO:tensorflow:Assets written to: /content/drive/MyDrive/RailCop/New Files/Sakib/models/__timeSeriesTest1.0/assets\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.6541 - accuracy: 0.6049 - val_loss: 0.6575 - val_accuracy: 0.6389 - lr: 0.0010\n",
            "Epoch 19/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.6154 - val_loss: 0.6587 - val_accuracy: 0.5972 - lr: 0.0010\n",
            "Epoch 20/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.6259 - val_loss: 0.6554 - val_accuracy: 0.6111 - lr: 0.0010\n",
            "Epoch 21/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.6573 - val_loss: 0.6604 - val_accuracy: 0.6111 - lr: 0.0010\n",
            "Epoch 22/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.6399 - val_loss: 0.6572 - val_accuracy: 0.6111 - lr: 0.0010\n",
            "Epoch 23/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.6259 - val_loss: 0.6586 - val_accuracy: 0.6389 - lr: 0.0010\n",
            "Epoch 24/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.6399 - val_loss: 0.6675 - val_accuracy: 0.6111 - lr: 0.0010\n",
            "Epoch 25/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.6259 - val_loss: 0.6621 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 26/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.6538 - val_loss: 0.6641 - val_accuracy: 0.6389 - lr: 5.0000e-04\n",
            "Epoch 27/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.6434 - val_loss: 0.6650 - val_accuracy: 0.6389 - lr: 5.0000e-04\n",
            "Epoch 28/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.6434 - val_loss: 0.6673 - val_accuracy: 0.5833 - lr: 5.0000e-04\n",
            "Epoch 29/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6573 - val_loss: 0.6653 - val_accuracy: 0.5972 - lr: 5.0000e-04\n",
            "Epoch 30/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6198 - accuracy: 0.6573 - val_loss: 0.6675 - val_accuracy: 0.5833 - lr: 5.0000e-04\n",
            "Epoch 31/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.6678 - val_loss: 0.6675 - val_accuracy: 0.6389 - lr: 2.5000e-04\n",
            "Epoch 32/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.6573 - val_loss: 0.6679 - val_accuracy: 0.6389 - lr: 2.5000e-04\n",
            "Epoch 33/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6164 - accuracy: 0.6538 - val_loss: 0.6682 - val_accuracy: 0.6389 - lr: 2.5000e-04\n",
            "Epoch 34/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.6643 - val_loss: 0.6688 - val_accuracy: 0.6389 - lr: 2.5000e-04\n",
            "Epoch 35/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.6573 - val_loss: 0.6693 - val_accuracy: 0.6389 - lr: 2.5000e-04\n",
            "Epoch 36/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6643 - val_loss: 0.6689 - val_accuracy: 0.6389 - lr: 1.2500e-04\n",
            "Epoch 37/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.6643 - val_loss: 0.6692 - val_accuracy: 0.6389 - lr: 1.2500e-04\n",
            "Epoch 38/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.6643 - val_loss: 0.6692 - val_accuracy: 0.6389 - lr: 1.2500e-04\n",
            "Epoch 39/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.6643 - val_loss: 0.6700 - val_accuracy: 0.6389 - lr: 1.2500e-04\n",
            "Epoch 40/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6678 - val_loss: 0.6702 - val_accuracy: 0.6389 - lr: 1.2500e-04\n",
            "Epoch 41/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.6748 - val_loss: 0.6705 - val_accuracy: 0.6389 - lr: 6.2500e-05\n",
            "Epoch 42/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.6748 - val_loss: 0.6702 - val_accuracy: 0.6389 - lr: 6.2500e-05\n",
            "Epoch 43/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.6643 - val_loss: 0.6706 - val_accuracy: 0.6389 - lr: 6.2500e-05\n",
            "Epoch 44/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.6748 - val_loss: 0.6705 - val_accuracy: 0.6389 - lr: 6.2500e-05\n",
            "Epoch 45/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.6643 - val_loss: 0.6703 - val_accuracy: 0.6389 - lr: 6.2500e-05\n",
            "Epoch 46/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.6748 - val_loss: 0.6703 - val_accuracy: 0.6389 - lr: 3.1250e-05\n",
            "Epoch 47/600\n",
            "62/72 [========================>.....] - ETA: 0s - loss: 0.6026 - accuracy: 0.6815INFO:tensorflow:Assets written to: /content/drive/MyDrive/RailCop/New Files/Sakib/models/__timeSeriesTest1.0/assets\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.6096 - accuracy: 0.6783 - val_loss: 0.6704 - val_accuracy: 0.6528 - lr: 3.1250e-05\n",
            "Epoch 48/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.6818 - val_loss: 0.6703 - val_accuracy: 0.6528 - lr: 3.1250e-05\n",
            "Epoch 49/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.6783 - val_loss: 0.6704 - val_accuracy: 0.6389 - lr: 3.1250e-05\n",
            "Epoch 50/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6094 - accuracy: 0.6783 - val_loss: 0.6705 - val_accuracy: 0.6528 - lr: 3.1250e-05\n",
            "Epoch 51/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6783 - val_loss: 0.6705 - val_accuracy: 0.6528 - lr: 1.5625e-05\n",
            "Epoch 52/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6748 - val_loss: 0.6704 - val_accuracy: 0.6528 - lr: 1.5625e-05\n",
            "Epoch 53/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6091 - accuracy: 0.6748 - val_loss: 0.6705 - val_accuracy: 0.6528 - lr: 1.5625e-05\n",
            "Epoch 54/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.6748 - val_loss: 0.6706 - val_accuracy: 0.6528 - lr: 1.5625e-05\n",
            "Epoch 55/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.6748 - val_loss: 0.6707 - val_accuracy: 0.6389 - lr: 1.5625e-05\n",
            "Epoch 56/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.6748 - val_loss: 0.6706 - val_accuracy: 0.6389 - lr: 7.8125e-06\n",
            "Epoch 57/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.6748 - val_loss: 0.6707 - val_accuracy: 0.6389 - lr: 7.8125e-06\n",
            "Epoch 58/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.6713 - val_loss: 0.6707 - val_accuracy: 0.6389 - lr: 7.8125e-06\n",
            "Epoch 59/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.6783 - val_loss: 0.6707 - val_accuracy: 0.6389 - lr: 7.8125e-06\n",
            "Epoch 60/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.6748 - val_loss: 0.6707 - val_accuracy: 0.6389 - lr: 7.8125e-06\n",
            "Epoch 61/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.6783 - val_loss: 0.6707 - val_accuracy: 0.6389 - lr: 3.9063e-06\n",
            "Epoch 62/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.6783 - val_loss: 0.6707 - val_accuracy: 0.6389 - lr: 3.9063e-06\n",
            "Epoch 63/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.6748 - val_loss: 0.6707 - val_accuracy: 0.6389 - lr: 3.9063e-06\n",
            "Epoch 64/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.6748 - val_loss: 0.6707 - val_accuracy: 0.6389 - lr: 3.9063e-06\n",
            "Epoch 65/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.6748 - val_loss: 0.6707 - val_accuracy: 0.6389 - lr: 3.9063e-06\n",
            "Epoch 66/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6748 - val_loss: 0.6707 - val_accuracy: 0.6389 - lr: 1.9531e-06\n",
            "Epoch 67/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6748 - val_loss: 0.6707 - val_accuracy: 0.6389 - lr: 1.9531e-06\n",
            "Epoch 68/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6748 - val_loss: 0.6707 - val_accuracy: 0.6389 - lr: 1.9531e-06\n",
            "Epoch 69/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6748 - val_loss: 0.6707 - val_accuracy: 0.6389 - lr: 1.9531e-06\n",
            "Epoch 70/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6748 - val_loss: 0.6707 - val_accuracy: 0.6389 - lr: 1.9531e-06\n",
            "Epoch 71/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6748 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 72/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6748 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 73/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.6748 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 74/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6748 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 75/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6748 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 76/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.6748 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 77/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6748 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 78/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.6748 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 79/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6748 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 80/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 81/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6748 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 82/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.6748 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 83/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 84/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 85/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 86/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 87/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 88/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 89/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 90/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 91/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 92/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 93/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 94/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 95/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 96/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 97/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 98/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 99/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 100/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 101/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 102/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 103/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 104/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 105/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 106/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 107/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 108/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 109/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 110/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 111/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 112/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 113/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 114/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 115/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 116/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 117/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 118/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 119/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 120/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 121/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 122/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 123/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 124/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6708 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 125/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 126/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 127/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 128/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 129/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 130/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 131/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 132/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 133/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 134/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 135/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 136/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 137/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 138/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 139/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 140/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 141/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 142/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 143/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 144/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 145/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 146/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 147/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 148/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 149/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 150/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6748 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 151/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 152/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 153/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 154/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 155/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 156/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 157/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 158/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 159/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 160/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 161/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 162/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 163/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6748 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 164/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 165/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 166/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 167/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 168/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 169/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 170/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 171/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 172/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 173/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6748 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 174/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 175/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 176/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 177/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6748 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 178/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 179/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 180/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 181/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 182/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6709 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 183/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 184/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 185/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6748 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 186/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 187/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 188/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 189/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 190/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6748 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 191/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 192/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6748 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 193/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 194/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 195/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 196/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 197/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 198/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 199/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 200/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 201/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 202/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 203/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 204/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 205/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6389 - lr: 1.0000e-06\n",
            "Epoch 206/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 207/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 208/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 209/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 210/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 211/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6748 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 212/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 213/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 214/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 215/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 216/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 217/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 218/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 219/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 220/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 221/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 222/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 223/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6748 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 224/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 225/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 226/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 227/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 228/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 229/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 230/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 231/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 232/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 233/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 234/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 235/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6748 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 236/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 237/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 238/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 239/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 240/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6748 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 241/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 242/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 243/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 244/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 245/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 246/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 247/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 248/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 249/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 250/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 251/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 252/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 253/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 254/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 255/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6748 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 256/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6748 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 257/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 258/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 259/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 260/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 261/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6710 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 262/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 263/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 264/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6748 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 265/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 266/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 267/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 268/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 269/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 270/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 271/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 272/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 273/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 274/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 275/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 276/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 277/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 278/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6748 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 279/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 280/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 281/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 282/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 283/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 284/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6748 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 285/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 286/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 287/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6748 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 288/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 289/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 290/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6748 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 291/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 292/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 293/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 294/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6748 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 295/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 296/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 297/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.6748 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 298/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 299/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 300/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 301/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 302/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 303/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.6748 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 304/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6748 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 305/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 306/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6748 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 307/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 308/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 309/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 310/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 311/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 312/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 313/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 314/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 315/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 316/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 317/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 318/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 319/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 320/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 321/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 322/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 323/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 324/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 325/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 326/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 327/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 328/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 329/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 330/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 331/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 332/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 333/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 334/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 335/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 336/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 337/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 338/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 339/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 340/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 341/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 342/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 343/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 344/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 345/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 346/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 347/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 348/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 349/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 350/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 351/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 352/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 353/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 354/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 355/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 356/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 357/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 358/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 359/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 360/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 361/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 362/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 363/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 364/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 365/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 366/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 367/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 368/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 369/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6783 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 370/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 371/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6712 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 372/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 373/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 374/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 375/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 376/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 377/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 378/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 379/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 380/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 381/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 382/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 383/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 384/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 385/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 386/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 387/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 388/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 389/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 390/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 391/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 392/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 393/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 394/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 395/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 396/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 397/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 398/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 399/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 400/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 401/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 402/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 403/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 404/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 405/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 406/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 407/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 408/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 409/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 410/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 411/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 412/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 413/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 414/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 415/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 416/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 417/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 418/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 419/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 420/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 421/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6079 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 422/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 423/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 424/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 425/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 426/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 427/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 428/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6748 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 429/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 430/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6713 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 431/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 432/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6748 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 433/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 434/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6748 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 435/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6748 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 436/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 437/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 438/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6748 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 439/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6748 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 440/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 441/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 442/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6748 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 443/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 444/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 445/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 446/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6748 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 447/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 448/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 449/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6748 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 450/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 451/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6748 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 452/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 453/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 454/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 455/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 456/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 457/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 458/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 459/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 460/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 461/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.6748 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 462/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 463/600\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 464/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.6748 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 465/600\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6078 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 466/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 467/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.6783 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 468/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.6748 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 469/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.6748 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 470/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.6748 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 471/600\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.6748 - val_loss: 0.6714 - val_accuracy: 0.6528 - lr: 1.0000e-06\n",
            "Epoch 472/600\n",
            "66/72 [==========================>...] - ETA: 0s - loss: 0.6000 - accuracy: 0.6894"
          ]
        }
      ]
    }
  ]
}